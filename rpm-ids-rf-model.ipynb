{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10647102,"sourceType":"datasetVersion","datasetId":6592386}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom imblearn.over_sampling import SMOTE\nimport joblib\nimport re\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-03-01T23:44:56.810632Z","iopub.execute_input":"2025-03-01T23:44:56.811035Z","iopub.status.idle":"2025-03-01T23:44:56.816686Z","shell.execute_reply.started":"2025-03-01T23:44:56.811008Z","shell.execute_reply":"2025-03-01T23:44:56.815531Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"rpm_df = pd.read_csv('/kaggle/input/RPM_dataset.csv')\n\nrpm_df.columns = ['Timestamp', 'CAN ID', 'DLC', 'DATA0', 'DATA1', 'DATA2', 'DATA3', 'DATA4', 'DATA5', 'DATA6', 'DATA7', 'Flag']\nrpm_df.head()","metadata":{"execution":{"iopub.status.busy":"2025-03-01T23:45:12.991855Z","iopub.execute_input":"2025-03-01T23:45:12.992267Z","iopub.status.idle":"2025-03-01T23:45:22.922917Z","shell.execute_reply.started":"2025-03-01T23:45:12.992216Z","shell.execute_reply":"2025-03-01T23:45:22.921682Z"},"trusted":true},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"      Timestamp CAN ID  DLC DATA0 DATA1 DATA2 DATA3 DATA4 DATA5 DATA6 DATA7  \\\n0  1.478191e+09   018f    8    fe    3b    00    00    00    3c    00    00   \n1  1.478191e+09   0260    8    19    22    22    30    ff    8f    6e    3f   \n2  1.478191e+09   02a0    8    60    00    83    1d    96    02    bd    00   \n3  1.478191e+09   0329    8    dc    b8    7e    14    11    20    00    14   \n4  1.478191e+09   0545    8    d8    00    00    83    00    00    00    00   \n\n  Flag  \n0    R  \n1    R  \n2    R  \n3    R  \n4    R  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Timestamp</th>\n      <th>CAN ID</th>\n      <th>DLC</th>\n      <th>DATA0</th>\n      <th>DATA1</th>\n      <th>DATA2</th>\n      <th>DATA3</th>\n      <th>DATA4</th>\n      <th>DATA5</th>\n      <th>DATA6</th>\n      <th>DATA7</th>\n      <th>Flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.478191e+09</td>\n      <td>018f</td>\n      <td>8</td>\n      <td>fe</td>\n      <td>3b</td>\n      <td>00</td>\n      <td>00</td>\n      <td>00</td>\n      <td>3c</td>\n      <td>00</td>\n      <td>00</td>\n      <td>R</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.478191e+09</td>\n      <td>0260</td>\n      <td>8</td>\n      <td>19</td>\n      <td>22</td>\n      <td>22</td>\n      <td>30</td>\n      <td>ff</td>\n      <td>8f</td>\n      <td>6e</td>\n      <td>3f</td>\n      <td>R</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.478191e+09</td>\n      <td>02a0</td>\n      <td>8</td>\n      <td>60</td>\n      <td>00</td>\n      <td>83</td>\n      <td>1d</td>\n      <td>96</td>\n      <td>02</td>\n      <td>bd</td>\n      <td>00</td>\n      <td>R</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.478191e+09</td>\n      <td>0329</td>\n      <td>8</td>\n      <td>dc</td>\n      <td>b8</td>\n      <td>7e</td>\n      <td>14</td>\n      <td>11</td>\n      <td>20</td>\n      <td>00</td>\n      <td>14</td>\n      <td>R</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.478191e+09</td>\n      <td>0545</td>\n      <td>8</td>\n      <td>d8</td>\n      <td>00</td>\n      <td>00</td>\n      <td>83</td>\n      <td>00</td>\n      <td>00</td>\n      <td>00</td>\n      <td>00</td>\n      <td>R</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"rpm_df.nunique()","metadata":{"execution":{"iopub.status.busy":"2025-03-01T23:45:25.420945Z","iopub.execute_input":"2025-03-01T23:45:25.421306Z","iopub.status.idle":"2025-03-01T23:45:28.471498Z","shell.execute_reply.started":"2025-03-01T23:45:25.421278Z","shell.execute_reply":"2025-03-01T23:45:28.470350Z"},"trusted":true},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"Timestamp    4621701\nCAN ID            26\nDLC                2\nDATA0            113\nDATA1             85\nDATA2             89\nDATA3             28\nDATA4            192\nDATA5            256\nDATA6             80\nDATA7            256\nFlag               2\ndtype: int64"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"df_2 = rpm_df.copy()","metadata":{"execution":{"iopub.status.busy":"2025-03-01T23:45:29.867499Z","iopub.execute_input":"2025-03-01T23:45:29.868012Z","iopub.status.idle":"2025-03-01T23:45:30.347407Z","shell.execute_reply.started":"2025-03-01T23:45:29.867973Z","shell.execute_reply":"2025-03-01T23:45:30.346070Z"},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"code","source":"missing_values = df_2.isnull().sum()\nmissing_values","metadata":{"execution":{"iopub.status.busy":"2025-03-01T23:45:31.320631Z","iopub.execute_input":"2025-03-01T23:45:31.321012Z","iopub.status.idle":"2025-03-01T23:45:33.553186Z","shell.execute_reply.started":"2025-03-01T23:45:31.320981Z","shell.execute_reply":"2025-03-01T23:45:33.552215Z"},"trusted":true},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"Timestamp        0\nCAN ID           0\nDLC              0\nDATA0            0\nDATA1            0\nDATA2            0\nDATA3        41476\nDATA4        41476\nDATA5        41476\nDATA6        41476\nDATA7        41476\nFlag         41476\ndtype: int64"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"df_dlc_is_2 = df_2[df_2[\"DLC\"] == 2].copy()\ndf_dlc_is_2.head(), df_dlc_is_2.shape","metadata":{"execution":{"iopub.status.busy":"2025-03-01T23:45:38.293947Z","iopub.execute_input":"2025-03-01T23:45:38.294322Z","iopub.status.idle":"2025-03-01T23:45:38.399592Z","shell.execute_reply.started":"2025-03-01T23:45:38.294288Z","shell.execute_reply":"2025-03-01T23:45:38.398506Z"},"trusted":true},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"(        Timestamp CAN ID  DLC DATA0 DATA1 DATA2 DATA3 DATA4 DATA5 DATA6 DATA7  \\\n 42   1.478191e+09   05f0    2    01    00     R   NaN   NaN   NaN   NaN   NaN   \n 134  1.478191e+09   05f0    2    01    00     R   NaN   NaN   NaN   NaN   NaN   \n 227  1.478191e+09   05f0    2    01    00     R   NaN   NaN   NaN   NaN   NaN   \n 319  1.478191e+09   05f0    2    01    00     R   NaN   NaN   NaN   NaN   NaN   \n 412  1.478191e+09   05f0    2    01    00     R   NaN   NaN   NaN   NaN   NaN   \n \n     Flag  \n 42   NaN  \n 134  NaN  \n 227  NaN  \n 319  NaN  \n 412  NaN  ,\n (41476, 12))"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"df_d2_nan = df_2[df_2[\"DATA2\"] == 'R'].copy()\ndf_d2_nan.head(), df_d2_nan.shape","metadata":{"execution":{"iopub.status.busy":"2025-03-01T23:45:41.274161Z","iopub.execute_input":"2025-03-01T23:45:41.274546Z","iopub.status.idle":"2025-03-01T23:45:41.670808Z","shell.execute_reply.started":"2025-03-01T23:45:41.274519Z","shell.execute_reply":"2025-03-01T23:45:41.669582Z"},"trusted":true},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"(        Timestamp CAN ID  DLC DATA0 DATA1 DATA2 DATA3 DATA4 DATA5 DATA6 DATA7  \\\n 42   1.478191e+09   05f0    2    01    00     R   NaN   NaN   NaN   NaN   NaN   \n 134  1.478191e+09   05f0    2    01    00     R   NaN   NaN   NaN   NaN   NaN   \n 227  1.478191e+09   05f0    2    01    00     R   NaN   NaN   NaN   NaN   NaN   \n 319  1.478191e+09   05f0    2    01    00     R   NaN   NaN   NaN   NaN   NaN   \n 412  1.478191e+09   05f0    2    01    00     R   NaN   NaN   NaN   NaN   NaN   \n \n     Flag  \n 42   NaN  \n 134  NaN  \n 227  NaN  \n 319  NaN  \n 412  NaN  ,\n (41476, 12))"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"df_flag_nan = df_2[(df_2[\"Flag\"] != \"T\") & (df_2[\"Flag\"] != \"R\")]\ndf_flag_nan.head(10), df_flag_nan.shape","metadata":{"execution":{"iopub.status.busy":"2025-03-01T23:45:41.672213Z","iopub.execute_input":"2025-03-01T23:45:41.672519Z","iopub.status.idle":"2025-03-01T23:45:42.400513Z","shell.execute_reply.started":"2025-03-01T23:45:41.672495Z","shell.execute_reply":"2025-03-01T23:45:42.399359Z"},"trusted":true},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"(        Timestamp CAN ID  DLC DATA0 DATA1 DATA2 DATA3 DATA4 DATA5 DATA6 DATA7  \\\n 42   1.478191e+09   05f0    2    01    00     R   NaN   NaN   NaN   NaN   NaN   \n 134  1.478191e+09   05f0    2    01    00     R   NaN   NaN   NaN   NaN   NaN   \n 227  1.478191e+09   05f0    2    01    00     R   NaN   NaN   NaN   NaN   NaN   \n 319  1.478191e+09   05f0    2    01    00     R   NaN   NaN   NaN   NaN   NaN   \n 412  1.478191e+09   05f0    2    01    00     R   NaN   NaN   NaN   NaN   NaN   \n 504  1.478191e+09   05f0    2    01    00     R   NaN   NaN   NaN   NaN   NaN   \n 597  1.478191e+09   05f0    2    01    00     R   NaN   NaN   NaN   NaN   NaN   \n 689  1.478191e+09   05f0    2    01    00     R   NaN   NaN   NaN   NaN   NaN   \n 782  1.478191e+09   05f0    2    01    00     R   NaN   NaN   NaN   NaN   NaN   \n 874  1.478191e+09   05f0    2    01    00     R   NaN   NaN   NaN   NaN   NaN   \n \n     Flag  \n 42   NaN  \n 134  NaN  \n 227  NaN  \n 319  NaN  \n 412  NaN  \n 504  NaN  \n 597  NaN  \n 689  NaN  \n 782  NaN  \n 874  NaN  ,\n (41476, 12))"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"df_3 = df_2.copy()","metadata":{"execution":{"iopub.status.busy":"2025-03-01T23:45:49.398083Z","iopub.execute_input":"2025-03-01T23:45:49.398534Z","iopub.status.idle":"2025-03-01T23:45:49.861048Z","shell.execute_reply.started":"2025-03-01T23:45:49.398499Z","shell.execute_reply":"2025-03-01T23:45:49.860066Z"},"trusted":true},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# For rows with DLC=2, move 'R' from DATA2 to Flag\nmask = df_3[\"DLC\"] == 2\ndf_3.loc[mask, \"Flag\"] = df_3.loc[mask, \"DATA2\"]  # Copy 'R' to Flag\ndf_3.loc[mask, \"DATA2\"] = np.nan  # Set DATA2 to NaN for DLC=2\n\n\n\n# Verify alignment\nprint(df_3[df_3[\"DLC\"] == 2].head())","metadata":{"execution":{"iopub.status.busy":"2025-03-01T23:45:49.862327Z","iopub.execute_input":"2025-03-01T23:45:49.862594Z","iopub.status.idle":"2025-03-01T23:45:50.019431Z","shell.execute_reply.started":"2025-03-01T23:45:49.862570Z","shell.execute_reply":"2025-03-01T23:45:50.018193Z"},"trusted":true},"outputs":[{"name":"stdout","text":"        Timestamp CAN ID  DLC DATA0 DATA1 DATA2 DATA3 DATA4 DATA5 DATA6 DATA7  \\\n42   1.478191e+09   05f0    2    01    00   NaN   NaN   NaN   NaN   NaN   NaN   \n134  1.478191e+09   05f0    2    01    00   NaN   NaN   NaN   NaN   NaN   NaN   \n227  1.478191e+09   05f0    2    01    00   NaN   NaN   NaN   NaN   NaN   NaN   \n319  1.478191e+09   05f0    2    01    00   NaN   NaN   NaN   NaN   NaN   NaN   \n412  1.478191e+09   05f0    2    01    00   NaN   NaN   NaN   NaN   NaN   NaN   \n\n    Flag  \n42     R  \n134    R  \n227    R  \n319    R  \n412    R  \n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"df_4 = df_3.copy()","metadata":{"execution":{"iopub.status.busy":"2025-03-01T23:45:50.020909Z","iopub.execute_input":"2025-03-01T23:45:50.021179Z","iopub.status.idle":"2025-03-01T23:45:50.487674Z","shell.execute_reply.started":"2025-03-01T23:45:50.021157Z","shell.execute_reply":"2025-03-01T23:45:50.486551Z"},"trusted":true},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Fill NaN with hex 00\ndefault_hex = '00'\ndata_columns = ['DATA2', 'DATA3', 'DATA4', 'DATA5', 'DATA6', 'DATA7', 'Flag']\ndf_4[data_columns] = df_4[data_columns].fillna(default_hex)\nprint(df_4[df_4[\"DLC\"] == 2].head()), df_4[df_4[\"DLC\"] == 2].shape","metadata":{"execution":{"iopub.status.busy":"2025-03-01T23:45:50.489071Z","iopub.execute_input":"2025-03-01T23:45:50.489440Z","iopub.status.idle":"2025-03-01T23:45:54.480491Z","shell.execute_reply.started":"2025-03-01T23:45:50.489412Z","shell.execute_reply":"2025-03-01T23:45:54.479516Z"},"trusted":true},"outputs":[{"name":"stdout","text":"        Timestamp CAN ID  DLC DATA0 DATA1 DATA2 DATA3 DATA4 DATA5 DATA6 DATA7  \\\n42   1.478191e+09   05f0    2    01    00    00    00    00    00    00    00   \n134  1.478191e+09   05f0    2    01    00    00    00    00    00    00    00   \n227  1.478191e+09   05f0    2    01    00    00    00    00    00    00    00   \n319  1.478191e+09   05f0    2    01    00    00    00    00    00    00    00   \n412  1.478191e+09   05f0    2    01    00    00    00    00    00    00    00   \n\n    Flag  \n42     R  \n134    R  \n227    R  \n319    R  \n412    R  \n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"(None, (41476, 12))"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"df_4.head(), df_4.shape","metadata":{"execution":{"iopub.status.busy":"2025-03-01T23:45:54.482260Z","iopub.execute_input":"2025-03-01T23:45:54.482654Z","iopub.status.idle":"2025-03-01T23:45:54.493442Z","shell.execute_reply.started":"2025-03-01T23:45:54.482626Z","shell.execute_reply":"2025-03-01T23:45:54.492354Z"},"trusted":true},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"(      Timestamp CAN ID  DLC DATA0 DATA1 DATA2 DATA3 DATA4 DATA5 DATA6 DATA7  \\\n 0  1.478191e+09   018f    8    fe    3b    00    00    00    3c    00    00   \n 1  1.478191e+09   0260    8    19    22    22    30    ff    8f    6e    3f   \n 2  1.478191e+09   02a0    8    60    00    83    1d    96    02    bd    00   \n 3  1.478191e+09   0329    8    dc    b8    7e    14    11    20    00    14   \n 4  1.478191e+09   0545    8    d8    00    00    83    00    00    00    00   \n \n   Flag  \n 0    R  \n 1    R  \n 2    R  \n 3    R  \n 4    R  ,\n (4621701, 12))"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"df_4[(df_4[\"Flag\"] != \"T\") & (df_4[\"Flag\"] != \"R\")]\n","metadata":{"execution":{"iopub.status.busy":"2025-03-01T23:45:54.495100Z","iopub.execute_input":"2025-03-01T23:45:54.495461Z","iopub.status.idle":"2025-03-01T23:45:55.185175Z","shell.execute_reply.started":"2025-03-01T23:45:54.495432Z","shell.execute_reply":"2025-03-01T23:45:55.184118Z"},"trusted":true},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"Empty DataFrame\nColumns: [Timestamp, CAN ID, DLC, DATA0, DATA1, DATA2, DATA3, DATA4, DATA5, DATA6, DATA7, Flag]\nIndex: []","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Timestamp</th>\n      <th>CAN ID</th>\n      <th>DLC</th>\n      <th>DATA0</th>\n      <th>DATA1</th>\n      <th>DATA2</th>\n      <th>DATA3</th>\n      <th>DATA4</th>\n      <th>DATA5</th>\n      <th>DATA6</th>\n      <th>DATA7</th>\n      <th>Flag</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"df_4[df_4[\"DATA2\"] == 'R'].head()","metadata":{"execution":{"iopub.status.busy":"2025-03-01T23:45:55.186293Z","iopub.execute_input":"2025-03-01T23:45:55.186678Z","iopub.status.idle":"2025-03-01T23:45:55.537682Z","shell.execute_reply.started":"2025-03-01T23:45:55.186641Z","shell.execute_reply":"2025-03-01T23:45:55.536587Z"},"trusted":true},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"Empty DataFrame\nColumns: [Timestamp, CAN ID, DLC, DATA0, DATA1, DATA2, DATA3, DATA4, DATA5, DATA6, DATA7, Flag]\nIndex: []","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Timestamp</th>\n      <th>CAN ID</th>\n      <th>DLC</th>\n      <th>DATA0</th>\n      <th>DATA1</th>\n      <th>DATA2</th>\n      <th>DATA3</th>\n      <th>DATA4</th>\n      <th>DATA5</th>\n      <th>DATA6</th>\n      <th>DATA7</th>\n      <th>Flag</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"# Drop unnecessary columns\ndf_drop_dlc = df_4.drop([\"DLC\"], axis=1).copy()\ndf_drop_dlc.head()","metadata":{"execution":{"iopub.status.busy":"2025-03-01T23:45:55.538985Z","iopub.execute_input":"2025-03-01T23:45:55.539318Z","iopub.status.idle":"2025-03-01T23:45:58.328995Z","shell.execute_reply.started":"2025-03-01T23:45:55.539288Z","shell.execute_reply":"2025-03-01T23:45:58.327774Z"},"trusted":true},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"      Timestamp CAN ID DATA0 DATA1 DATA2 DATA3 DATA4 DATA5 DATA6 DATA7 Flag\n0  1.478191e+09   018f    fe    3b    00    00    00    3c    00    00    R\n1  1.478191e+09   0260    19    22    22    30    ff    8f    6e    3f    R\n2  1.478191e+09   02a0    60    00    83    1d    96    02    bd    00    R\n3  1.478191e+09   0329    dc    b8    7e    14    11    20    00    14    R\n4  1.478191e+09   0545    d8    00    00    83    00    00    00    00    R","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Timestamp</th>\n      <th>CAN ID</th>\n      <th>DATA0</th>\n      <th>DATA1</th>\n      <th>DATA2</th>\n      <th>DATA3</th>\n      <th>DATA4</th>\n      <th>DATA5</th>\n      <th>DATA6</th>\n      <th>DATA7</th>\n      <th>Flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.478191e+09</td>\n      <td>018f</td>\n      <td>fe</td>\n      <td>3b</td>\n      <td>00</td>\n      <td>00</td>\n      <td>00</td>\n      <td>3c</td>\n      <td>00</td>\n      <td>00</td>\n      <td>R</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.478191e+09</td>\n      <td>0260</td>\n      <td>19</td>\n      <td>22</td>\n      <td>22</td>\n      <td>30</td>\n      <td>ff</td>\n      <td>8f</td>\n      <td>6e</td>\n      <td>3f</td>\n      <td>R</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.478191e+09</td>\n      <td>02a0</td>\n      <td>60</td>\n      <td>00</td>\n      <td>83</td>\n      <td>1d</td>\n      <td>96</td>\n      <td>02</td>\n      <td>bd</td>\n      <td>00</td>\n      <td>R</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.478191e+09</td>\n      <td>0329</td>\n      <td>dc</td>\n      <td>b8</td>\n      <td>7e</td>\n      <td>14</td>\n      <td>11</td>\n      <td>20</td>\n      <td>00</td>\n      <td>14</td>\n      <td>R</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.478191e+09</td>\n      <td>0545</td>\n      <td>d8</td>\n      <td>00</td>\n      <td>00</td>\n      <td>83</td>\n      <td>00</td>\n      <td>00</td>\n      <td>00</td>\n      <td>00</td>\n      <td>R</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"df_drop_dlc.dtypes, df_drop_dlc.shape","metadata":{"execution":{"iopub.status.busy":"2025-03-01T23:45:58.331316Z","iopub.execute_input":"2025-03-01T23:45:58.331616Z","iopub.status.idle":"2025-03-01T23:45:58.338987Z","shell.execute_reply.started":"2025-03-01T23:45:58.331589Z","shell.execute_reply":"2025-03-01T23:45:58.337854Z"},"trusted":true},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"(Timestamp    float64\n CAN ID        object\n DATA0         object\n DATA1         object\n DATA2         object\n DATA3         object\n DATA4         object\n DATA5         object\n DATA6         object\n DATA7         object\n Flag          object\n dtype: object,\n (4621701, 11))"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"df_can_id_0000 = df_drop_dlc[df_drop_dlc[\"CAN ID\"] == \"0000\"]\ndf_can_id_0000.head(), df_can_id_0000.shape","metadata":{"execution":{"iopub.status.busy":"2025-03-01T23:45:58.340362Z","iopub.execute_input":"2025-03-01T23:45:58.340686Z","iopub.status.idle":"2025-03-01T23:45:58.721468Z","shell.execute_reply.started":"2025-03-01T23:45:58.340660Z","shell.execute_reply":"2025-03-01T23:45:58.720286Z"},"trusted":true},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"(Empty DataFrame\n Columns: [Timestamp, CAN ID, DATA0, DATA1, DATA2, DATA3, DATA4, DATA5, DATA6, DATA7, Flag]\n Index: [],\n (0, 11))"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"df_6 = df_drop_dlc.copy()\n\ndf_drop_timestamp = df_drop_dlc.drop(columns=['Timestamp'], inplace=False).copy()\ndf_drop_timestamp.describe()\n\n","metadata":{"execution":{"iopub.status.busy":"2025-03-01T23:45:58.722516Z","iopub.execute_input":"2025-03-01T23:45:58.722906Z","iopub.status.idle":"2025-03-01T23:46:05.489110Z","shell.execute_reply.started":"2025-03-01T23:45:58.722875Z","shell.execute_reply":"2025-03-01T23:46:05.488164Z"},"trusted":true},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"         CAN ID    DATA0    DATA1    DATA2    DATA3    DATA4    DATA5  \\\ncount   4621701  4621701  4621701  4621701  4621701  4621701  4621701   \nunique       26      113       85       88       28      192      256   \ntop        0316       00       00       00       00       00       00   \nfreq     871230  1467124  1710232  2406008  1888765  1790965  1298354   \n\n          DATA6    DATA7     Flag  \ncount   4621701  4621701  4621701  \nunique       80      256        2  \ntop          00       00        R  \nfreq    2822119  2131776  3966804  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CAN ID</th>\n      <th>DATA0</th>\n      <th>DATA1</th>\n      <th>DATA2</th>\n      <th>DATA3</th>\n      <th>DATA4</th>\n      <th>DATA5</th>\n      <th>DATA6</th>\n      <th>DATA7</th>\n      <th>Flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>4621701</td>\n      <td>4621701</td>\n      <td>4621701</td>\n      <td>4621701</td>\n      <td>4621701</td>\n      <td>4621701</td>\n      <td>4621701</td>\n      <td>4621701</td>\n      <td>4621701</td>\n      <td>4621701</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>26</td>\n      <td>113</td>\n      <td>85</td>\n      <td>88</td>\n      <td>28</td>\n      <td>192</td>\n      <td>256</td>\n      <td>80</td>\n      <td>256</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>0316</td>\n      <td>00</td>\n      <td>00</td>\n      <td>00</td>\n      <td>00</td>\n      <td>00</td>\n      <td>00</td>\n      <td>00</td>\n      <td>00</td>\n      <td>R</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>871230</td>\n      <td>1467124</td>\n      <td>1710232</td>\n      <td>2406008</td>\n      <td>1888765</td>\n      <td>1790965</td>\n      <td>1298354</td>\n      <td>2822119</td>\n      <td>2131776</td>\n      <td>3966804</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"data_columns = ['DATA0', 'DATA1', 'DATA2', 'DATA3', 'DATA4', 'DATA5', 'DATA6', 'DATA7']\n\n# Create regex pattern for valid hex\nhex_pattern = r'^[0-9A-Fa-f]{2}$'\n\n# Check for non-hex values\nmask = df_6[data_columns].apply(lambda col: ~col.str.match(hex_pattern, na=False))\n\n# Get rows with any invalid entries\ninvalid_rows = df_6[mask.any(axis=1)]\n\nprint(\"Rows with non-hex values in DATA columns:\")\nprint(invalid_rows if not invalid_rows.empty else \"No non-hex values found\")","metadata":{"execution":{"iopub.status.busy":"2025-03-01T23:46:48.736220Z","iopub.execute_input":"2025-03-01T23:46:48.736562Z","iopub.status.idle":"2025-03-01T23:47:05.762900Z","shell.execute_reply.started":"2025-03-01T23:46:48.736535Z","shell.execute_reply":"2025-03-01T23:47:05.761878Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Rows with non-hex values in DATA columns:\nNo non-hex values found\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"df_7 = df_6.copy()\n# Function to convert hex to decimal\ndef hex_to_int(hex_str: str) -> int:\n    try:\n        return int(str(hex_str).strip(), 16)  # Convert hex to int\n    except ValueError:\n        return np.nan \n\n# Convert all DATA columns\nfor col in df_7.columns[1:-1]:  # Exclude 'Flag' column\n    df_7[col] = df_7[col].apply(hex_to_int)\n\ndf_7.head()","metadata":{"execution":{"iopub.status.busy":"2025-03-01T23:47:05.763807Z","iopub.execute_input":"2025-03-01T23:47:05.764077Z","iopub.status.idle":"2025-03-01T23:47:31.481583Z","shell.execute_reply.started":"2025-03-01T23:47:05.764054Z","shell.execute_reply":"2025-03-01T23:47:31.480507Z"},"trusted":true},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"      Timestamp  CAN ID  DATA0  DATA1  DATA2  DATA3  DATA4  DATA5  DATA6  \\\n0  1.478191e+09     399    254     59      0      0      0     60      0   \n1  1.478191e+09     608     25     34     34     48    255    143    110   \n2  1.478191e+09     672     96      0    131     29    150      2    189   \n3  1.478191e+09     809    220    184    126     20     17     32      0   \n4  1.478191e+09    1349    216      0      0    131      0      0      0   \n\n   DATA7 Flag  \n0      0    R  \n1     63    R  \n2      0    R  \n3     20    R  \n4      0    R  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Timestamp</th>\n      <th>CAN ID</th>\n      <th>DATA0</th>\n      <th>DATA1</th>\n      <th>DATA2</th>\n      <th>DATA3</th>\n      <th>DATA4</th>\n      <th>DATA5</th>\n      <th>DATA6</th>\n      <th>DATA7</th>\n      <th>Flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.478191e+09</td>\n      <td>399</td>\n      <td>254</td>\n      <td>59</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>60</td>\n      <td>0</td>\n      <td>0</td>\n      <td>R</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.478191e+09</td>\n      <td>608</td>\n      <td>25</td>\n      <td>34</td>\n      <td>34</td>\n      <td>48</td>\n      <td>255</td>\n      <td>143</td>\n      <td>110</td>\n      <td>63</td>\n      <td>R</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.478191e+09</td>\n      <td>672</td>\n      <td>96</td>\n      <td>0</td>\n      <td>131</td>\n      <td>29</td>\n      <td>150</td>\n      <td>2</td>\n      <td>189</td>\n      <td>0</td>\n      <td>R</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.478191e+09</td>\n      <td>809</td>\n      <td>220</td>\n      <td>184</td>\n      <td>126</td>\n      <td>20</td>\n      <td>17</td>\n      <td>32</td>\n      <td>0</td>\n      <td>20</td>\n      <td>R</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.478191e+09</td>\n      <td>1349</td>\n      <td>216</td>\n      <td>0</td>\n      <td>0</td>\n      <td>131</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>R</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"df_8 = df_7.copy()","metadata":{"execution":{"iopub.status.busy":"2025-03-01T23:47:31.483293Z","iopub.execute_input":"2025-03-01T23:47:31.483625Z","iopub.status.idle":"2025-03-01T23:47:32.015848Z","shell.execute_reply.started":"2025-03-01T23:47:31.483597Z","shell.execute_reply":"2025-03-01T23:47:32.014718Z"},"trusted":true},"outputs":[],"execution_count":34},{"cell_type":"code","source":"df_8[\"Flag\"] = df_8[\"Flag\"].map({\"R\": 0, \"T\": 1})\ndf_8.head()","metadata":{"execution":{"iopub.status.busy":"2025-03-01T23:47:32.016999Z","iopub.execute_input":"2025-03-01T23:47:32.017266Z","iopub.status.idle":"2025-03-01T23:47:32.207475Z","shell.execute_reply.started":"2025-03-01T23:47:32.017224Z","shell.execute_reply":"2025-03-01T23:47:32.206359Z"},"trusted":true},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"      Timestamp  CAN ID  DATA0  DATA1  DATA2  DATA3  DATA4  DATA5  DATA6  \\\n0  1.478191e+09     399    254     59      0      0      0     60      0   \n1  1.478191e+09     608     25     34     34     48    255    143    110   \n2  1.478191e+09     672     96      0    131     29    150      2    189   \n3  1.478191e+09     809    220    184    126     20     17     32      0   \n4  1.478191e+09    1349    216      0      0    131      0      0      0   \n\n   DATA7  Flag  \n0      0     0  \n1     63     0  \n2      0     0  \n3     20     0  \n4      0     0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Timestamp</th>\n      <th>CAN ID</th>\n      <th>DATA0</th>\n      <th>DATA1</th>\n      <th>DATA2</th>\n      <th>DATA3</th>\n      <th>DATA4</th>\n      <th>DATA5</th>\n      <th>DATA6</th>\n      <th>DATA7</th>\n      <th>Flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.478191e+09</td>\n      <td>399</td>\n      <td>254</td>\n      <td>59</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>60</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.478191e+09</td>\n      <td>608</td>\n      <td>25</td>\n      <td>34</td>\n      <td>34</td>\n      <td>48</td>\n      <td>255</td>\n      <td>143</td>\n      <td>110</td>\n      <td>63</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.478191e+09</td>\n      <td>672</td>\n      <td>96</td>\n      <td>0</td>\n      <td>131</td>\n      <td>29</td>\n      <td>150</td>\n      <td>2</td>\n      <td>189</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.478191e+09</td>\n      <td>809</td>\n      <td>220</td>\n      <td>184</td>\n      <td>126</td>\n      <td>20</td>\n      <td>17</td>\n      <td>32</td>\n      <td>0</td>\n      <td>20</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.478191e+09</td>\n      <td>1349</td>\n      <td>216</td>\n      <td>0</td>\n      <td>0</td>\n      <td>131</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"df_8[\"Flag\"].unique()","metadata":{"execution":{"iopub.status.busy":"2025-03-01T23:47:32.208397Z","iopub.execute_input":"2025-03-01T23:47:32.208725Z","iopub.status.idle":"2025-03-01T23:47:32.244977Z","shell.execute_reply.started":"2025-03-01T23:47:32.208700Z","shell.execute_reply":"2025-03-01T23:47:32.244030Z"},"trusted":true},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"array([0, 1])"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"df_8.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2025-03-01T23:47:32.245839Z","iopub.execute_input":"2025-03-01T23:47:32.246083Z","iopub.status.idle":"2025-03-01T23:47:32.340621Z","shell.execute_reply.started":"2025-03-01T23:47:32.246063Z","shell.execute_reply":"2025-03-01T23:47:32.339484Z"},"trusted":true},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"Timestamp    0\nCAN ID       0\nDATA0        0\nDATA1        0\nDATA2        0\nDATA3        0\nDATA4        0\nDATA5        0\nDATA6        0\nDATA7        0\nFlag         0\ndtype: int64"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"df_8.info()","metadata":{"execution":{"iopub.status.busy":"2025-03-01T23:47:32.341297Z","iopub.execute_input":"2025-03-01T23:47:32.341551Z","iopub.status.idle":"2025-03-01T23:47:32.439867Z","shell.execute_reply.started":"2025-03-01T23:47:32.341530Z","shell.execute_reply":"2025-03-01T23:47:32.438504Z"},"trusted":true},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 4621701 entries, 0 to 4621700\nData columns (total 11 columns):\n #   Column     Dtype  \n---  ------     -----  \n 0   Timestamp  float64\n 1   CAN ID     int64  \n 2   DATA0      int64  \n 3   DATA1      int64  \n 4   DATA2      int64  \n 5   DATA3      int64  \n 6   DATA4      int64  \n 7   DATA5      int64  \n 8   DATA6      int64  \n 9   DATA7      int64  \n 10  Flag       int64  \ndtypes: float64(1), int64(10)\nmemory usage: 387.9 MB\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"df_8.describe()","metadata":{"execution":{"iopub.status.busy":"2025-03-01T23:47:32.441040Z","iopub.execute_input":"2025-03-01T23:47:32.441460Z","iopub.status.idle":"2025-03-01T23:47:34.348110Z","shell.execute_reply.started":"2025-03-01T23:47:32.441411Z","shell.execute_reply":"2025-03-01T23:47:34.347086Z"},"trusted":true},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"          Timestamp        CAN ID         DATA0         DATA1         DATA2  \\\ncount  4.621701e+06  4.621701e+06  4.621701e+06  4.621701e+06  4.621701e+06   \nmean   1.478194e+09  7.151190e+02  6.028397e+01  4.256768e+01  3.530757e+01   \nstd    3.565417e+03  3.505162e+02  8.686002e+01  4.973679e+01  5.134037e+01   \nmin    1.478191e+09  2.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n25%    1.478192e+09  3.990000e+02  0.000000e+00  0.000000e+00  0.000000e+00   \n50%    1.478192e+09  7.900000e+02  1.600000e+01  3.300000e+01  0.000000e+00   \n75%    1.478193e+09  8.800000e+02  6.900000e+01  4.100000e+01  3.600000e+01   \nmax    1.478201e+09  1.680000e+03  2.550000e+02  1.920000e+02  2.520000e+02   \n\n              DATA3         DATA4         DATA5         DATA6         DATA7  \\\ncount  4.621701e+06  4.621701e+06  4.621701e+06  4.621701e+06  4.621701e+06   \nmean   9.074923e+01  5.346931e+01  6.175567e+01  2.246208e+01  7.470137e+01   \nstd    1.092712e+02  7.584148e+01  7.354858e+01  5.328198e+01  9.750145e+01   \nmin    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n50%    2.000000e+01  2.200000e+01  3.600000e+01  0.000000e+00  1.900000e+01   \n75%    2.550000e+02  5.900000e+01  1.270000e+02  8.000000e+00  1.420000e+02   \nmax    2.550000e+02  2.550000e+02  2.550000e+02  2.090000e+02  2.550000e+02   \n\n               Flag  \ncount  4.621701e+06  \nmean   1.417004e-01  \nstd    3.487427e-01  \nmin    0.000000e+00  \n25%    0.000000e+00  \n50%    0.000000e+00  \n75%    0.000000e+00  \nmax    1.000000e+00  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Timestamp</th>\n      <th>CAN ID</th>\n      <th>DATA0</th>\n      <th>DATA1</th>\n      <th>DATA2</th>\n      <th>DATA3</th>\n      <th>DATA4</th>\n      <th>DATA5</th>\n      <th>DATA6</th>\n      <th>DATA7</th>\n      <th>Flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>4.621701e+06</td>\n      <td>4.621701e+06</td>\n      <td>4.621701e+06</td>\n      <td>4.621701e+06</td>\n      <td>4.621701e+06</td>\n      <td>4.621701e+06</td>\n      <td>4.621701e+06</td>\n      <td>4.621701e+06</td>\n      <td>4.621701e+06</td>\n      <td>4.621701e+06</td>\n      <td>4.621701e+06</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.478194e+09</td>\n      <td>7.151190e+02</td>\n      <td>6.028397e+01</td>\n      <td>4.256768e+01</td>\n      <td>3.530757e+01</td>\n      <td>9.074923e+01</td>\n      <td>5.346931e+01</td>\n      <td>6.175567e+01</td>\n      <td>2.246208e+01</td>\n      <td>7.470137e+01</td>\n      <td>1.417004e-01</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>3.565417e+03</td>\n      <td>3.505162e+02</td>\n      <td>8.686002e+01</td>\n      <td>4.973679e+01</td>\n      <td>5.134037e+01</td>\n      <td>1.092712e+02</td>\n      <td>7.584148e+01</td>\n      <td>7.354858e+01</td>\n      <td>5.328198e+01</td>\n      <td>9.750145e+01</td>\n      <td>3.487427e-01</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.478191e+09</td>\n      <td>2.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.478192e+09</td>\n      <td>3.990000e+02</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.478192e+09</td>\n      <td>7.900000e+02</td>\n      <td>1.600000e+01</td>\n      <td>3.300000e+01</td>\n      <td>0.000000e+00</td>\n      <td>2.000000e+01</td>\n      <td>2.200000e+01</td>\n      <td>3.600000e+01</td>\n      <td>0.000000e+00</td>\n      <td>1.900000e+01</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.478193e+09</td>\n      <td>8.800000e+02</td>\n      <td>6.900000e+01</td>\n      <td>4.100000e+01</td>\n      <td>3.600000e+01</td>\n      <td>2.550000e+02</td>\n      <td>5.900000e+01</td>\n      <td>1.270000e+02</td>\n      <td>8.000000e+00</td>\n      <td>1.420000e+02</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.478201e+09</td>\n      <td>1.680000e+03</td>\n      <td>2.550000e+02</td>\n      <td>1.920000e+02</td>\n      <td>2.520000e+02</td>\n      <td>2.550000e+02</td>\n      <td>2.550000e+02</td>\n      <td>2.550000e+02</td>\n      <td>2.090000e+02</td>\n      <td>2.550000e+02</td>\n      <td>1.000000e+00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"# df_8.to_csv('/kaggle/working/cleaned_data.csv', index=False)\n\n# print(\"Data saved successfully as 'cleaned_data.csv'.\")","metadata":{"execution":{"iopub.execute_input":"2025-02-28T02:03:21.156886Z","iopub.status.busy":"2025-02-28T02:03:21.156559Z","iopub.status.idle":"2025-02-28T02:03:21.160286Z","shell.execute_reply":"2025-02-28T02:03:21.159249Z","shell.execute_reply.started":"2025-02-28T02:03:21.156859Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Exclude the 'Flag' column before calculating correlation\ncorrelation_matrix = df_8.drop(columns=['Timestamp', 'CAN ID', 'Flag']).corr()\ncorrelation_matrix","metadata":{"execution":{"iopub.execute_input":"2025-02-28T02:03:23.153053Z","iopub.status.busy":"2025-02-28T02:03:23.152720Z","iopub.status.idle":"2025-02-28T02:03:24.060648Z","shell.execute_reply":"2025-02-28T02:03:24.059790Z","shell.execute_reply.started":"2025-02-28T02:03:23.153025Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Assuming 'correlation_matrix' is already computed\nplt.figure(figsize=(8, 6))\n\n# Plot the correlation matrix as a heatmap\nsns.heatmap(correlation_matrix, annot=True, fmt='.2f', linewidths=0.5)\n\n# Save the plot as a PNG image\nplt.tight_layout()  # Ensures that the layout doesn't get cropped\nplt.savefig('correlation_matrix_heatmap.png', dpi=300, bbox_inches='tight')\n\n# Optionally, display the plot (if needed)\n# plt.show()\n","metadata":{"execution":{"iopub.execute_input":"2025-02-28T02:03:30.009784Z","iopub.status.busy":"2025-02-28T02:03:30.009461Z","iopub.status.idle":"2025-02-28T02:03:30.684651Z","shell.execute_reply":"2025-02-28T02:03:30.683734Z","shell.execute_reply.started":"2025-02-28T02:03:30.009760Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_9 = df_8.copy()\ndf_9.head()","metadata":{"execution":{"iopub.execute_input":"2025-02-28T02:03:34.874841Z","iopub.status.busy":"2025-02-28T02:03:34.874449Z","iopub.status.idle":"2025-02-28T02:03:35.197952Z","shell.execute_reply":"2025-02-28T02:03:35.196970Z","shell.execute_reply.started":"2025-02-28T02:03:34.874811Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Realistic Scenario with no CAN ID included\n\n## Algorithm Selection XGB","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport xgboost as xgb\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, roc_curve, auc\n\n# Load data\ndf = df_9.drop(columns=['Timestamp']).copy()\n\n# 1. Preprocessing\n# Convert CAN ID to numerical (already done as 0 for attacks)\ndf['CAN ID'] = df['CAN ID'].astype('int64')\n\n# 2. Define features and target variable\nX = df.drop(['Flag', 'CAN ID'], axis=1)  # Remove the leakage feature\ny = df['Flag']\n\n# 3. Split data with stratification\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, \n    test_size=0.2, \n    stratify=y, \n    random_state=42\n)\n\n# 4. Initialize XGBoost with realistic parameters\nmodel = xgb.XGBClassifier(\n    scale_pos_weight=8,\n    objective='binary:logistic',\n    eval_metric='aucpr',\n    use_label_encoder=False,\n    max_depth=6,  # Prevent overfitting\n    subsample=0.8,\n    colsample_bytree=0.8,\n    random_state=42\n)\n\n# 5. Train the model\nmodel.fit(X_train, y_train)\n\n# 6. Evaluate\ny_pred = model.predict(X_test)\ny_proba = model.predict_proba(X_test)[:, 1]\n\n# Print metrics\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\nprint(f\"\\nROC AUC Score: {roc_auc_score(y_test, y_proba):.4f}\")\n\n# 7. Feature Importance\nplt.figure(figsize=(10, 6))\nplt.title(\"Feature Importances (Without CAN ID Leakage)\")\nxgb.plot_importance(model, ax=plt.gca())\nplt.tight_layout()\nplt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')\nplt.show()\n\n# 1. Plot Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(6, 4))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.tight_layout()\nplt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\nplt.show()\n\n# 2. Plot ROC Curve\nfpr, tpr, thresholds = roc_curve(y_test, y_proba)\nroc_auc = auc(fpr, tpr)\n\nplt.figure(figsize=(6, 4))\nplt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.4f})')\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC)')\nplt.legend(loc=\"lower right\")\nplt.tight_layout()\nplt.savefig('roc_curve.png', dpi=300, bbox_inches='tight')\nplt.show()\n","metadata":{"execution":{"iopub.execute_input":"2025-02-28T02:04:52.720077Z","iopub.status.busy":"2025-02-28T02:04:52.719731Z","iopub.status.idle":"2025-02-28T02:05:05.607162Z","shell.execute_reply":"2025-02-28T02:05:05.606286Z","shell.execute_reply.started":"2025-02-28T02:04:52.720048Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from sklearn.model_selection import GridSearchCV\n\n# param_grid = {\n#     'max_depth': [3, 6, 9],\n#     'learning_rate': [0.01, 0.1, 0.2],\n#     'n_estimators': [50, 100, 200]\n# }\n\n# grid_search = GridSearchCV(xgb.XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\"),\n#                            param_grid, scoring='roc_auc', cv=3, n_jobs=-1)\n# grid_search.fit(X_train, y_train)\n# print(\"Best parameters:\", grid_search.best_params_)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##  Advanced Feature Engineering","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve\nimport xgboost as xgb\n\n# Load dataset\ndf = df_9.copy()\nprint(df.columns)\n\n\n# Define feature columns and target\nfeatures = ['DATA0', 'DATA1', 'DATA5', 'DATA7']\nX = df[features]\ny = df['Flag']  # Target: 1 = Attack, 0 = Normal\n\n# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train XGBoost model\nmodel = xgb.XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.1, use_label_encoder=False, eval_metric=\"logloss\")\nmodel.fit(X_train, y_train)\n\n# Predictions\ny_pred = model.predict(X_test)\ny_proba = model.predict_proba(X_test)[:, 1]  # Probability scores\n\n# Performance Metrics\nprint(classification_report(y_test, y_pred))\nroc_auc = roc_auc_score(y_test, y_proba)\nprint(f\"ROC AUC Score: {roc_auc:.4f}\")\n\n# Precision-Recall Curve & Optimal Threshold\nprecision, recall, thresholds = precision_recall_curve(y_test, y_proba)\ntarget_recall = 0.95\nidx = np.argmax(recall >= target_recall)\noptimal_threshold = thresholds[idx]\nprint(f\"Optimal Decision Threshold: {optimal_threshold:.2f}\")\n\nbest_idx = np.argmax(precision * recall)  # F1-score based tuning\nbest_threshold = thresholds[best_idx]\nprint(f\"New Optimal Threshold: {best_threshold:.2f}\")\n\n\n# Feature Importance Analysis\n# plt.figure(figsize=(8, 5))\n# xgb.plot_importance(model, importance_type='weight', title=\"Feature Importance\")\n# plt.show()\n\n# Byte-Level Analysis\nplt.figure(figsize=(12, 6))\nfor i, feature in enumerate(features[:2]):  # DATA0 and DATA1\n    plt.subplot(1, 2, i + 1)\n    sns.histplot(df[df['Flag'] == 0][feature], label='Normal', color='blue', kde=True, alpha=0.6)\n    sns.histplot(df[df['Flag'] == 1][feature], label='Attack', color='red', kde=True, alpha=0.6)\n    plt.title(f\"Distribution of {feature}\")\n    plt.legend()\n\nplt.show()\n\n# Feature Engineering (Bitwise & Arithmetic Transformations)\ndf['DATA01 XOR'] = df['DATA0'] ^ df['DATA1']\ndf['DATA01 SUM'] = df['DATA0'] + df['DATA1']\ndf['DATA57 XOR'] = df['DATA5'] ^ df['DATA7']\n\nprint(df[['DATA01 XOR', 'DATA01 SUM', 'DATA57 XOR']].describe()) \n\n# Train again with engineered features\nX_new = df[['DATA0', 'DATA1', 'DATA5', 'DATA7', 'DATA01 XOR', 'DATA01 SUM', 'DATA57 XOR']]\nX_train_new, X_test_new, y_train, y_test = train_test_split(X_new, y, test_size=0.2, random_state=42)\nmodel.fit(X_train_new, y_train)\n\n# Evaluate again\ny_pred_new = model.predict(X_test_new)\nprint(classification_report(y_test, y_pred_new))\n","metadata":{"execution":{"iopub.execute_input":"2025-02-28T02:09:32.460020Z","iopub.status.busy":"2025-02-28T02:09:32.459677Z","iopub.status.idle":"2025-02-28T02:10:20.705445Z","shell.execute_reply":"2025-02-28T02:10:20.704386Z","shell.execute_reply.started":"2025-02-28T02:09:32.459990Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_9.head()","metadata":{"execution":{"iopub.execute_input":"2025-02-28T02:10:26.582877Z","iopub.status.busy":"2025-02-28T02:10:26.582561Z","iopub.status.idle":"2025-02-28T02:10:26.593882Z","shell.execute_reply":"2025-02-28T02:10:26.593063Z","shell.execute_reply.started":"2025-02-28T02:10:26.582851Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Temporal Features","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nimport xgboost as xgb\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom imblearn.over_sampling import SMOTE  # Import for oversampling\nfrom sklearn.metrics import roc_auc_score\n\n# Load data\ndf = df_9.copy()\n\n# Ensure Timestamp is in datetime format\ndf['Timestamp'] = pd.to_datetime(df['Timestamp'], unit='s')  # Adjust unit if needed\n\n# Sort values by Timestamp and reset the index\ndf = df.sort_values('Timestamp').reset_index(drop=True)\n\n# Set 'Timestamp' as the index for rolling operations\ndf.set_index('Timestamp', inplace=True)\n\n# 2. Global time-based features (no ECU grouping)\ndf['Global_Time_Delta'] = df.index.to_series().diff().dt.total_seconds().fillna(0)  # Time between ALL messages\n\n# 3. Rolling count of messages in 1s and 5s window\ndf['Rolling_Count_DoS_1ms'] = df.rolling('1ms').count()['CAN ID']\ndf['Rolling_Count_DoS_10ms'] = df.rolling('10ms').count()['CAN ID']\n\n# 4. Frequency-based features (DoS Attack detection)\ndf['Rolling_Count_DoS_1ms'] = df.rolling('0.3ms').count()['CAN ID']  # Messages in 0.3ms window (for DoS attack)\n\n# 5. Frequency/Time features\ndf['Hour'] = df.index.hour\ndf['Time_Since_First_Message'] = (df.index - df.index.min()).total_seconds()\n\n# 6. Prepare features (drop the identifier columns but don't drop 'Timestamp' since it's the index)\nX = df.drop(['Flag', 'CAN ID'], axis=1)  # Keep 'Is_DoS_Attack'\ny = df['Flag']\n\n# 1. Apply SMOTE for oversampling to handle class imbalance\nsmote = SMOTE(sampling_strategy='auto', random_state=42)\nX_res, y_res = smote.fit_resample(X, y)\n\n# Initialize XGBoost with realistic parameters and scale_pos_weight\nmodel = xgb.XGBClassifier(\n    scale_pos_weight=10,  # Adjusting to 10\n    objective='binary:logistic',\n    eval_metric='aucpr',\n    use_label_encoder=False,\n    max_depth=6,  # Prevent overfitting\n    subsample=0.8,\n    colsample_bytree=0.8,\n    random_state=42\n)\n\n# 2. Initialize StratifiedKFold for 5-Fold Cross Validation\nkf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n# 3. Cross-validation loop\nroc_auc_scores = []\naccuracies = []\nclassification_reports = []\nconfusion_matrices = []\n\nfor train_index, test_index in kf.split(X_res, y_res):\n    X_train, X_test = X_res.iloc[train_index], X_res.iloc[test_index]\n    y_train, y_test = y_res.iloc[train_index], y_res.iloc[test_index]\n\n    # Train the model on resampled data\n    model.fit(X_train, y_train)\n\n    # Predict and evaluate the model\n    y_pred = model.predict(X_test)\n    y_proba = model.predict_proba(X_test)[:, 1]\n\n    # Check shapes\n    print(f\"Shape of y_test: {y_test.shape}\")\n    print(f\"Shape of y_pred: {y_pred.shape}\")\n\n    # Calculate metrics\n    accuracies.append(accuracy_score(y_test, y_pred))\n    roc_auc_scores.append(roc_auc_score(y_test, y_proba))\n    classification_reports.append(classification_report(y_test, y_pred))\n    confusion_matrices.append(confusion_matrix(y_test, y_pred))\n\n# Print average results after cross-validation\nprint(f\"Average Accuracy: {np.mean(accuracies):.4f}\")\nprint(f\"Average ROC AUC Score: {np.mean(roc_auc_scores):.4f}\")\nprint(f\"Unique values in y_res: {np.unique(y_res)}\")\n\n\n# Confusion Matrix - Average of all 5 folds\navg_conf_matrix = np.mean(confusion_matrices, axis=0)\nprint(f\"\\nAverage Confusion Matrix:\\n {avg_conf_matrix}\")\n\n# Classification Report - Average of all 5 folds (not directly average-able, but print for one fold)\nprint(\"\\nClassification Report (example of one fold):\\n\", classification_reports[0])\n\n# 4. Feature Importance\n# Get feature importances\nfeature_importances = model.feature_importances_\n\n# Extract feature importances from the model\nimportances = model.get_booster().get_score(importance_type='gain')  # Get 'gain' importance\n\n# Normalize the importance values to make them sum to 1\nnormalized_importances = {feature: imp / sum(importances.values()) for feature, imp in importances.items()}\n\n# Create a DataFrame for the feature importances\nfeature_importance_df = pd.DataFrame(list(normalized_importances.items()), columns=['Feature', 'Importance'])\n\n# Sort features by importance\nfeature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n\n# 1. Plot Feature Importance using XGBoost's internal plot (using normalized 'gain')\nplt.figure(figsize=(10, 6))\nplt.title(\"Feature Importances (Including DoS Attack Detection)\")\nxgb.plot_importance(model, importance_type='gain', ax=plt.gca())  # Use 'gain' for consistency\nplt.show()\n\n# 2. Plot Feature Importance using Heatmap for better visualization (Normalized values)\nplt.figure(figsize=(8, 6))\nsns.heatmap(feature_importance_df.set_index('Feature').T, annot=True, cmap='coolwarm', cbar=False, fmt='.3f', annot_kws={'size': 12})\nplt.title('Feature Importance Table')\nplt.tight_layout()\nplt.show()\n\n# Print the feature importance table\nprint(\"\\nFeature Importances (Normalized):\\n\", feature_importance_df)\n\n\n# Plot ROC Curve for each fold\nfpr, tpr, thresholds = roc_curve(y_test, y_proba)\nplt.figure(figsize=(8, 6))\nplt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {roc_auc_score(y_test, y_proba):.4f})')\nplt.plot([0, 1], [0, 1], color='gray', linestyle='--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title(f'ROC Curve - Fold {len(roc_auc_scores)}')\nplt.legend(loc='lower right')\nplt.show()\n\n# Plot Confusion Matrix for each fold\ncm = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, xticklabels=['Normal', 'DoS Attack'], yticklabels=['Normal', 'DoS Attack'])\nplt.title(f'Confusion Matrix - Fold {len(confusion_matrices)}')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.show()\n\n\n# #Hyperparameter Tuning using GridSearchCV\n# from sklearn.model_selection import GridSearchCV\n# from imblearn.pipeline import Pipeline  # To avoid data leakage\n\n# # Define pipeline with SMOTE and XGBoost\n# pipeline = Pipeline([\n#     ('smote', SMOTE(sampling_strategy='auto', random_state=42)),  # Oversampling\n#     ('xgb', xgb.XGBClassifier(use_label_encoder=False, eval_metric=\"aucpr\"))\n# ])\n\n# # Define parameter grid\n# param_grid = {\n#     'xgb__max_depth': [4, 6, 8],  \n#     'xgb__learning_rate': [0.01, 0.1],  \n#     'xgb__subsample': [0.8, 1.0]\n# }\n\n# # Perform Grid Search\n# grid_search = GridSearchCV(pipeline, param_grid, scoring='roc_auc', cv=3, n_jobs=-1, verbose=2)\n# grid_search.fit(X, y)  # Use original X, y (not resampled)\n\n# # Print best parameters\n# print(\"Best parameters:\", grid_search.best_params_)\n\n","metadata":{"execution":{"iopub.execute_input":"2025-02-28T02:24:50.981605Z","iopub.status.busy":"2025-02-28T02:24:50.981263Z","iopub.status.idle":"2025-02-28T02:27:23.068306Z","shell.execute_reply":"2025-02-28T02:27:23.067520Z","shell.execute_reply.started":"2025-02-28T02:24:50.981577Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Code with GridSearch","metadata":{}},{"cell_type":"code","source":"# import pandas as pd\n# import numpy as np\n# from sklearn.model_selection import train_test_split, StratifiedKFold\n# import xgboost as xgb\n# from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score\n# import matplotlib.pyplot as plt\n# import seaborn as sns\n# from imblearn.over_sampling import SMOTE  # Import for oversampling\n# from sklearn.metrics import roc_auc_score\n# from sklearn.model_selection import GridSearchCV, StratifiedKFold\n# from imblearn.pipeline import Pipeline  # Use imblearn's Pipeline for SMOTE integration\n\n# # Load data\n# df = df_9.copy()\n\n# # Ensure Timestamp is in datetime format\n# df['Timestamp'] = pd.to_datetime(df['Timestamp'], unit='s')  # Adjust unit if needed\n\n# # Sort values by Timestamp and reset the index\n# df = df.sort_values('Timestamp').reset_index(drop=True)\n\n# # Set 'Timestamp' as the index for rolling operations\n# df.set_index('Timestamp', inplace=True)\n\n# # 2. Global time-based features (no ECU grouping)\n# df['Global_Time_Delta'] = df.index.to_series().diff().dt.total_seconds().fillna(0)  # Time between ALL messages\n\n# # 3. Rolling count of messages in 1s and 5s window\n# df['Rolling_Count_DoS_1ms'] = df.rolling('1ms').count()['CAN ID']\n# df['Rolling_Count_DoS_10ms'] = df.rolling('10ms').count()['CAN ID']\n\n# # 4. Frequency-based features (DoS Attack detection)\n# df['Rolling_Count_DoS_1ms'] = df.rolling('0.3ms').count()['CAN ID']  # Messages in 0.3ms window (for DoS attack)\n\n# # 5. Frequency/Time features\n# df['Hour'] = df.index.hour\n# df['Time_Since_First_Message'] = (df.index - df.index.min()).total_seconds()\n\n# # 6. Prepare features (drop the identifier columns but don't drop 'Timestamp' since it's the index)\n\n\n# # Load data and prepare features (same as before)\n# df = df_9.copy()\n# df['Timestamp'] = pd.to_datetime(df['Timestamp'], unit='s')\n# df = df.sort_values('Timestamp').reset_index(drop=True)\n# df.set_index('Timestamp', inplace=True)\n\n# # ... [Your existing feature engineering code] ...\n\n# # Prepare X and y (do NOT apply SMOTE here)\n# X = df.drop(['Flag', 'CAN ID'], axis=1)\n# y = df['Flag']\n\n# # Define the pipeline: SMOTE -> XGBoost\n# pipeline = Pipeline([\n#     ('smote', SMOTE(random_state=42)),\n#     ('xgb', xgb.XGBClassifier(\n#         objective='binary:logistic',\n#         eval_metric='aucpr',\n#         use_label_encoder=False,\n#         random_state=42\n#     ))\n# ])\n\n# # Define hyperparameter grid\n# param_grid = {\n#     'xgb__max_depth': [4, 6],  # Test shallow and deeper trees\n#     'xgb__learning_rate': [0.01, 0.1],  # Step size for boosting\n#     'xgb__n_estimators': [100, 200],  # Number of trees\n#     'xgb__subsample': [0.8, 1.0],  # Fraction of samples per tree\n#     'xgb__colsample_bytree': [0.8, 1.0],  # Fraction of features per tree\n#     'xgb__scale_pos_weight': [1, 5, 10]  # Handle class imbalance\n# }\n\n# # Configure GridSearchCV\n# kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n# grid_search = GridSearchCV(\n#     estimator=pipeline,\n#     param_grid=param_grid,\n#     scoring='roc_auc',  # Prioritize AUC for class imbalance\n#     cv=kf,\n#     n_jobs=-1,  # Use all CPU cores\n#     verbose=2\n# )\n\n# # Run Grid Search on original data (X, y)\n# grid_search.fit(X, y)\n\n# # Get the best model\n# best_model = grid_search.best_estimator_\n# print(f\"Best Parameters: {grid_search.best_params_}\")\n# print(f\"Best ROC AUC: {grid_search.best_score_:.4f}\")\n\n\n# # Predict using the best model\n# y_pred = best_model.predict(X_test)\n# y_proba = best_model.predict_proba(X_test)[:, 1]\n\n# # Evaluate metrics\n# print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n# print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))\n# print(classification_report(y_test, y_pred))\n# print(confusion_matrix(y_test, y_pred))\n","metadata":{"execution":{"iopub.status.busy":"2025-02-28T02:24:48.495520Z","iopub.status.idle":"2025-02-28T02:24:48.495763Z","shell.execute_reply":"2025-02-28T02:24:48.495662Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Updated Confusion Matrix:\n```\ncm = [[605815   9834]\n      [    72 615578]]\n```\n\n### Explanation:\n- **True Positives (TP)**: The number of instances correctly predicted as **Class 1** (attack).\n  - **615578** (bottom-right cell)\n  \n- **False Positives (FP)**: The number of instances incorrectly predicted as **Class 1** when they are actually **Class 0** (normal).\n  - **9834** (top-right cell)\n\n- **True Negatives (TN)**: The number of instances correctly predicted as **Class 0** (normal).\n  - **605815** (top-left cell)\n\n- **False Negatives (FN)**: The number of instances incorrectly predicted as **Class 0** when they are actually **Class 1**.\n  - **72** (bottom-left cell)\n\n### Now, let's compute some key metrics:\n\n1. **Accuracy**: The overall percentage of correct predictions.\n   \\[\n   \\text{Accuracy} = \\frac{TP + TN}{TP + FP + TN + FN}\n   \\]\n   \\[\n   \\text{Accuracy} = \\frac{615578 + 605815}{615578 + 9834 + 605815 + 72} = \\frac{1227393}{1227399} \\approx 0.99995\n   \\]\n   **Accuracy  99.995%**\n\n2. **Precision for Class 1 (attack)**: The percentage of predicted positive instances (Class 1) that are actually positive.\n   \\[\n   \\text{Precision (Class 1)} = \\frac{TP}{TP + FP} = \\frac{615578}{615578 + 9834} \\approx 0.983\n   \\]\n   **Precision (Class 1)  98.3%**\n\n3. **Recall for Class 1 (attack)**: The percentage of actual positive instances (Class 1) that were correctly identified.\n   \\[\n   \\text{Recall (Class 1)} = \\frac{TP}{TP + FN} = \\frac{615578}{615578 + 72} \\approx 0.99988\n   \\]\n   **Recall (Class 1)  99.99%**\n\n4. **F1 Score for Class 1**: The harmonic mean of precision and recall.\n   \\[\n   \\text{F1 Score (Class 1)} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}} \\approx 2 \\times \\frac{0.983 \\times 0.99988}{0.983 + 0.99988} \\approx 0.991\n   \\]\n   **F1 Score (Class 1)  99.1%**\n\n5. **Precision for Class 0 (normal)**: The percentage of predicted negative instances (Class 0) that are actually negative.\n   \\[\n   \\text{Precision (Class 0)} = \\frac{TN}{TN + FN} = \\frac{605815}{605815 + 72} \\approx 0.99988\n   \\]\n   **Precision (Class 0)  99.99%**\n\n6. **Recall for Class 0 (normal)**: The percentage of actual negative instances (Class 0) that were correctly identified.\n   \\[\n   \\text{Recall (Class 0)} = \\frac{TN}{TN + FP} = \\frac{605815}{605815 + 9834} \\approx 0.984\n   \\]\n   **Recall (Class 0)  98.4%**\n\n7. **F1 Score for Class 0**: The harmonic mean of precision and recall for Class 0.\n   \\[\n   \\text{F1 Score (Class 0)} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}} \\approx 2 \\times \\frac{0.99988 \\times 0.984}{0.99988 + 0.984} \\approx 0.992\n   \\]\n   **F1 Score (Class 0)  99.2%**\n\n### Conclusion:\n- **Accuracy**: 99.995%, which suggests that the model is correct nearly 100% of the time.\n- **For Class 1 (attack)**: The model performs very well with a high **precision** (98.3%) and **recall** (99.99%), making it excellent at detecting **attacks**.\n- **For Class 0 (normal)**: The model also performs excellently for **normal** instances with a **precision** of 99.99% and **recall** of 98.4%.\n\nThe model appears to be performing very well overall, especially for both classes. The **attack class** (Class 1) has very few false negatives, and the **normal class** (Class 0) has very few false positives. However, you may want to look into **class imbalance**, since the numbers of instances of Class 1 and Class 0 may be quite different. But for this case, the model is performing well in distinguishing both classes.","metadata":{}},{"cell_type":"markdown","source":"## Hyperparameter Tuning using GridSearchCV","metadata":{}},{"cell_type":"markdown","source":"## Algorithm RF","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\n\n# Load data\ndf = df_9.copy()\n\n# 2. Split data\nX = df.drop(['Flag', 'CAN ID'], axis=1)  # Remove the leakage feature\ny = df['Flag']\n\n# Stratified split to maintain class balance\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, \n    test_size=0.2, \n    stratify=y,\n    random_state=42\n)\n\n# 3. Initialize Random Forest with class weighting\nrf = RandomForestClassifier(\n    n_estimators=100,\n    class_weight='balanced',  # Handles imbalance\n    max_depth=10,             # Prevent overfitting\n    n_jobs=-1,                # Use all cores\n    random_state=42\n)\n\n# 4. Train model\nrf.fit(X_train, y_train)\n\n# 5. Evaluate\ny_pred = rf.predict(X_test)\ny_proba = rf.predict_proba(X_test)[:,1]\n\n# Evaluate model performance\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n\nprint(f\"\\nROC AUC Score: {roc_auc_score(y_test, y_proba):.4f}\")\n\n# 6. Feature Importance\nfeatures = X.columns\nimportances = rf.feature_importances_\nstd = np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)\n\n# Create DataFrame\nfi_df = pd.DataFrame({'Feature': features, 'Importance': importances, 'Std': std})\nfi_df = fi_df.sort_values('Importance', ascending=False)\n\n# Plot\nplt.figure(figsize=(10,6))\nplt.title(\"Feature Importances\")\nplt.bar(fi_df['Feature'], fi_df['Importance'], yerr=fi_df['Std'])\nplt.xticks(rotation=45)\nplt.show()","metadata":{"execution":{"iopub.execute_input":"2025-02-28T02:32:48.548931Z","iopub.status.busy":"2025-02-28T02:32:48.548598Z","iopub.status.idle":"2025-02-28T02:33:54.879736Z","shell.execute_reply":"2025-02-28T02:33:54.878904Z","shell.execute_reply.started":"2025-02-28T02:32:48.548908Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Class Weight Tuning","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score\nimport matplotlib.pyplot as plt\n\n# Load data\ndf = df_9.copy()\n\n\n# 2. Split data\nX = df.drop(['Timestamp', 'Flag', 'CAN ID'], axis=1)  # Remove the leakage feature\ny = df['Flag']\n\n# Stratified split to maintain class balance\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, \n    test_size=0.2, \n    stratify=y,\n    random_state=42\n)\n\n# 3. Manually calculate class weights based on the exact class ratio (~5.24:1)\n# ratio = 3_078_250 / 587_521  # approximately 5.24\nratio = 10\nclass_weights = {0: 1, 1: ratio}  # Assign higher weight to minority class\n\n# 4. Initialize Random Forest with manually calculated class weights\nrf = RandomForestClassifier(\n    n_estimators=100,\n    class_weight=class_weights,  # using manual weights instead of 'balanced'\n    max_depth=10,                # Prevent overfitting\n    n_jobs=-1,                   # Use all available cores\n    random_state=42\n)\n\n# 5. Train the model\nrf.fit(X_train, y_train)\n\n# 6. Evaluate the model\ny_pred = rf.predict(X_test)\ny_proba = rf.predict_proba(X_test)[:, 1]\n\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\nprint(f\"\\nROC AUC Score: {roc_auc_score(y_test, y_proba):.4f}\")\n\n# 7. Feature Importance\nfeatures = X.columns\nimportances = rf.feature_importances_\nstd = np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)\n\n# Create DataFrame for feature importances\nfi_df = pd.DataFrame({'Feature': features, 'Importance': importances, 'Std': std})\nfi_df = fi_df.sort_values('Importance', ascending=False)\n\n# Plot feature importances\nplt.figure(figsize=(10, 6))\nplt.title(\"Feature Importances\")\nplt.bar(fi_df['Feature'], fi_df['Importance'], yerr=fi_df['Std'])\nplt.xticks(rotation=45)\nplt.show()\n","metadata":{"execution":{"iopub.execute_input":"2025-02-28T02:41:26.435090Z","iopub.status.busy":"2025-02-28T02:41:26.434764Z","iopub.status.idle":"2025-02-28T02:42:23.661819Z","shell.execute_reply":"2025-02-28T02:42:23.661014Z","shell.execute_reply.started":"2025-02-28T02:41:26.435066Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Threshold Adjustment","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport xgboost as xgb\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score, precision_recall_curve\nimport matplotlib.pyplot as plt\n\n# Load data\ndf = df_9.copy()\n\n\nX = df.drop(['Timestamp', 'Flag', 'CAN ID'], axis=1)  # Remove the leakage feature\ny = df['Flag']\n\n# 3. Split data with stratification to maintain class balance\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, \n    test_size=0.2, \n    stratify=y, \n    random_state=42\n)\n\n# 4. Initialize XGBoost classifier with built-in imbalance handling\nmodel = xgb.XGBClassifier(\n    scale_pos_weight=5.24,      # Directly accounts for the class imbalance ratio\n    objective='binary:logistic',\n    eval_metric='aucpr',        # Optimize for precision-recall AUC\n    use_label_encoder=False,    # Suppress a warning regarding label encoding\n    random_state=42\n)\n\n# 5. Train the model\nmodel.fit(X_train, y_train)\n\n# 6. Get predicted probabilities for the positive class\ny_proba = model.predict_proba(X_test)[:, 1]\n\n# 7. Threshold Adjustment: Optimize decision threshold using precision-recall curve\nprecision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n\n# Compute F1 scores for each threshold; note that thresholds array is one element shorter than precision/recall\nf1_scores = 2 * precision[:-1] * recall[:-1] / (precision[:-1] + recall[:-1] + 1e-8)  # avoid division by zero\nbest_idx = np.argmax(f1_scores)\nbest_threshold = thresholds[best_idx]\nprint(f\"Optimal Threshold (based on maximum F1): {best_threshold:.4f}\")\n\n# Use the optimal threshold to make final predictions\ny_pred = (y_proba >= best_threshold).astype(int)\n\n# 8. Evaluate the model with the adjusted threshold\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\nprint(f\"\\nROC AUC Score: {roc_auc_score(y_test, y_proba):.4f}\")\n\n# 9. Feature Importance Plot\nplt.figure(figsize=(10, 6))\nplt.title(\"Feature Importances (XGBoost)\")\nxgb.plot_importance(model, ax=plt.gca())\nplt.show()\n","metadata":{"execution":{"iopub.execute_input":"2025-02-28T02:35:49.943815Z","iopub.status.busy":"2025-02-28T02:35:49.943518Z","iopub.status.idle":"2025-02-28T02:36:01.197174Z","shell.execute_reply":"2025-02-28T02:36:01.196347Z","shell.execute_reply.started":"2025-02-28T02:35:49.943793Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Hyperparameter Tuning:","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = {\n    'n_estimators': [100, 200],\n    'max_depth': [10, 20],\n    'min_samples_split': [2, 5]\n}\n\ngrid_search = GridSearchCV(rf, param_grid, cv=3, scoring='roc_auc')\ngrid_search.fit(X_train, y_train)\n\nprint(\"Best parameters found:\", grid_search.best_params_)\nbest_rf = grid_search.best_estimator_\n\n# Evaluate the tuned model\ny_pred_tuned = best_rf.predict(X_test)\nprint(\"Tuned Model Accuracy:\", accuracy_score(y_test, y_pred_tuned))\n\n\n\n","metadata":{"execution":{"iopub.execute_input":"2025-02-28T02:54:15.193372Z","iopub.status.busy":"2025-02-28T02:54:15.193048Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"2. **Advanced Handling of CAN ID**:","metadata":{}},{"cell_type":"code","source":"   # Create interaction features between CAN ID and data bytes\n   df['CAN_ID_Interaction'] = df['CAN ID'].astype(str) + '_' + df['DATA0'].astype(str)","metadata":{"execution":{"iopub.status.busy":"2025-02-27T23:43:02.035452Z","iopub.status.idle":"2025-02-27T23:43:02.035843Z","shell.execute_reply":"2025-02-27T23:43:02.035676Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"3. **Dimensionality Reduction**:","metadata":{}},{"cell_type":"code","source":" from sklearn.decomposition import PCA\n   \n   pca = PCA(n_components=5)\n   X_pca = pca.fit_transform(X)","metadata":{"execution":{"iopub.status.busy":"2025-02-27T23:43:02.036723Z","iopub.status.idle":"2025-02-27T23:43:02.037176Z","shell.execute_reply":"2025-02-27T23:43:02.036993Z"},"trusted":true},"outputs":[],"execution_count":null}]}