{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10647102,"sourceType":"datasetVersion","datasetId":6592386}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom imblearn.over_sampling import SMOTE\nimport joblib\nimport re\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true,"execution":{"iopub.status.busy":"2025-03-05T15:13:27.680170Z","iopub.execute_input":"2025-03-05T15:13:27.680445Z","iopub.status.idle":"2025-03-05T15:13:29.767887Z","shell.execute_reply.started":"2025-03-05T15:13:27.680419Z","shell.execute_reply":"2025-03-05T15:13:29.766984Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"gear_df = pd.read_csv('/kaggle/input/gear_dataset.csv')\n\ngear_df.columns = ['Timestamp', 'CAN ID', 'DLC', 'DATA0', 'DATA1', 'DATA2', 'DATA3', 'DATA4', 'DATA5', 'DATA6', 'DATA7', 'Flag']\ngear_df.head()","metadata":{"execution":{"iopub.status.busy":"2025-03-05T15:13:29.769623Z","iopub.execute_input":"2025-03-05T15:13:29.770018Z","iopub.status.idle":"2025-03-05T15:13:38.021913Z","shell.execute_reply.started":"2025-03-05T15:13:29.769993Z","shell.execute_reply":"2025-03-05T15:13:38.020966Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"gear_df.nunique()","metadata":{"execution":{"iopub.status.busy":"2025-03-05T15:13:38.023461Z","iopub.execute_input":"2025-03-05T15:13:38.023857Z","iopub.status.idle":"2025-03-05T15:13:40.497950Z","shell.execute_reply.started":"2025-03-05T15:13:38.023820Z","shell.execute_reply":"2025-03-05T15:13:40.496868Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_2 = gear_df.copy()","metadata":{"execution":{"iopub.status.busy":"2025-03-05T15:13:40.498956Z","iopub.execute_input":"2025-03-05T15:13:40.499331Z","iopub.status.idle":"2025-03-05T15:13:40.835242Z","shell.execute_reply.started":"2025-03-05T15:13:40.499297Z","shell.execute_reply":"2025-03-05T15:13:40.834317Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"missing_values = df_2.isnull().sum()\nmissing_values","metadata":{"execution":{"iopub.status.busy":"2025-03-05T15:13:40.836090Z","iopub.execute_input":"2025-03-05T15:13:40.836348Z","iopub.status.idle":"2025-03-05T15:13:42.622256Z","shell.execute_reply.started":"2025-03-05T15:13:40.836327Z","shell.execute_reply":"2025-03-05T15:13:42.621374Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_dlc_is_2 = df_2[df_2[\"DLC\"] == 2].copy()\ndf_dlc_is_2.head(), df_dlc_is_2.shape","metadata":{"execution":{"iopub.status.busy":"2025-03-05T15:13:42.624636Z","iopub.execute_input":"2025-03-05T15:13:42.624891Z","iopub.status.idle":"2025-03-05T15:13:42.681889Z","shell.execute_reply.started":"2025-03-05T15:13:42.624870Z","shell.execute_reply":"2025-03-05T15:13:42.680904Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_d2_nan = df_2[df_2[\"DATA2\"] == 'R'].copy()\ndf_d2_nan.head(), df_d2_nan.shape","metadata":{"execution":{"iopub.status.busy":"2025-03-05T15:13:42.683404Z","iopub.execute_input":"2025-03-05T15:13:42.683669Z","iopub.status.idle":"2025-03-05T15:13:42.996879Z","shell.execute_reply.started":"2025-03-05T15:13:42.683648Z","shell.execute_reply":"2025-03-05T15:13:42.995822Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_flag_nan = df_2[(df_2[\"Flag\"] != \"T\") & (df_2[\"Flag\"] != \"R\")]\ndf_flag_nan.head(10), df_flag_nan.shape","metadata":{"execution":{"iopub.status.busy":"2025-03-05T15:13:42.997767Z","iopub.execute_input":"2025-03-05T15:13:42.998014Z","iopub.status.idle":"2025-03-05T15:13:43.552225Z","shell.execute_reply.started":"2025-03-05T15:13:42.997993Z","shell.execute_reply":"2025-03-05T15:13:43.551179Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_3 = df_2.copy()","metadata":{"execution":{"iopub.status.busy":"2025-03-05T15:13:43.553291Z","iopub.execute_input":"2025-03-05T15:13:43.553613Z","iopub.status.idle":"2025-03-05T15:13:43.894877Z","shell.execute_reply.started":"2025-03-05T15:13:43.553586Z","shell.execute_reply":"2025-03-05T15:13:43.893753Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# For rows with DLC=2, move 'R' from DATA2 to Flag\nmask = df_3[\"DLC\"] == 2\ndf_3.loc[mask, \"Flag\"] = df_3.loc[mask, \"DATA2\"]  # Copy 'R' to Flag\ndf_3.loc[mask, \"DATA2\"] = np.nan  # Set DATA2 to NaN for DLC=2\n\n\n\n# Verify alignment\nprint(df_3[df_3[\"DLC\"] == 2].head())","metadata":{"execution":{"iopub.status.busy":"2025-03-05T15:13:43.895936Z","iopub.execute_input":"2025-03-05T15:13:43.896301Z","iopub.status.idle":"2025-03-05T15:13:44.023826Z","shell.execute_reply.started":"2025-03-05T15:13:43.896268Z","shell.execute_reply":"2025-03-05T15:13:44.022962Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_4 = df_3.copy()","metadata":{"execution":{"iopub.status.busy":"2025-03-05T15:13:44.024865Z","iopub.execute_input":"2025-03-05T15:13:44.025204Z","iopub.status.idle":"2025-03-05T15:13:44.383090Z","shell.execute_reply.started":"2025-03-05T15:13:44.025171Z","shell.execute_reply":"2025-03-05T15:13:44.382239Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fill NaN with hex 00\ndefault_hex = '00'\ndata_columns = ['DATA2', 'DATA3', 'DATA4', 'DATA5', 'DATA6', 'DATA7', 'Flag']\ndf_4[data_columns] = df_4[data_columns].fillna(default_hex)\nprint(df_4[df_4[\"DLC\"] == 2].head()), df_4[df_4[\"DLC\"] == 2].shape","metadata":{"execution":{"iopub.status.busy":"2025-03-05T15:13:44.384017Z","iopub.execute_input":"2025-03-05T15:13:44.384279Z","iopub.status.idle":"2025-03-05T15:13:47.494346Z","shell.execute_reply.started":"2025-03-05T15:13:44.384257Z","shell.execute_reply":"2025-03-05T15:13:47.493510Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_4.head(), df_4.shape","metadata":{"execution":{"iopub.status.busy":"2025-03-05T15:13:47.495304Z","iopub.execute_input":"2025-03-05T15:13:47.495582Z","iopub.status.idle":"2025-03-05T15:13:47.505687Z","shell.execute_reply.started":"2025-03-05T15:13:47.495531Z","shell.execute_reply":"2025-03-05T15:13:47.504652Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_4[(df_4[\"Flag\"] != \"T\") & (df_4[\"Flag\"] != \"R\")]\n","metadata":{"execution":{"iopub.status.busy":"2025-03-05T15:13:47.506801Z","iopub.execute_input":"2025-03-05T15:13:47.507122Z","iopub.status.idle":"2025-03-05T15:13:48.046318Z","shell.execute_reply.started":"2025-03-05T15:13:47.507084Z","shell.execute_reply":"2025-03-05T15:13:48.045457Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_4[df_4[\"DATA2\"] == 'R'].head()","metadata":{"execution":{"iopub.status.busy":"2025-03-05T15:13:48.047303Z","iopub.execute_input":"2025-03-05T15:13:48.047666Z","iopub.status.idle":"2025-03-05T15:13:48.326723Z","shell.execute_reply.started":"2025-03-05T15:13:48.047616Z","shell.execute_reply":"2025-03-05T15:13:48.325688Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Drop unnecessary columns\ndf_drop_dlc = df_4.drop([\"DLC\"], axis=1).copy()\ndf_drop_dlc.head()","metadata":{"execution":{"iopub.status.busy":"2025-03-05T15:13:48.327563Z","iopub.execute_input":"2025-03-05T15:13:48.327850Z","iopub.status.idle":"2025-03-05T15:13:50.448978Z","shell.execute_reply.started":"2025-03-05T15:13:48.327824Z","shell.execute_reply":"2025-03-05T15:13:50.447768Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_drop_dlc.dtypes, df_drop_dlc.shape","metadata":{"execution":{"iopub.status.busy":"2025-03-05T15:13:50.450072Z","iopub.execute_input":"2025-03-05T15:13:50.450470Z","iopub.status.idle":"2025-03-05T15:13:50.457582Z","shell.execute_reply.started":"2025-03-05T15:13:50.450402Z","shell.execute_reply":"2025-03-05T15:13:50.456615Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_can_id_0000 = df_drop_dlc[df_drop_dlc[\"CAN ID\"] == \"0000\"]\ndf_can_id_0000.head(), df_can_id_0000.shape","metadata":{"execution":{"iopub.status.busy":"2025-03-05T15:13:50.462483Z","iopub.execute_input":"2025-03-05T15:13:50.462765Z","iopub.status.idle":"2025-03-05T15:13:50.824866Z","shell.execute_reply.started":"2025-03-05T15:13:50.462743Z","shell.execute_reply":"2025-03-05T15:13:50.823988Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_6 = df_drop_dlc.copy()\n\ndf_drop_timestamp = df_drop_dlc.drop(columns=['Timestamp'], inplace=False).copy()\ndf_drop_timestamp.describe()\n\n","metadata":{"execution":{"iopub.status.busy":"2025-03-05T15:13:50.826474Z","iopub.execute_input":"2025-03-05T15:13:50.826741Z","iopub.status.idle":"2025-03-05T15:13:56.260215Z","shell.execute_reply.started":"2025-03-05T15:13:50.826719Z","shell.execute_reply":"2025-03-05T15:13:56.259207Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_columns = ['DATA0', 'DATA1', 'DATA2', 'DATA3', 'DATA4', 'DATA5', 'DATA6', 'DATA7']\n\n# Create regex pattern for valid hex\nhex_pattern = r'^[0-9A-Fa-f]{2}$'\n\n# Check for non-hex values\nmask = df_6[data_columns].apply(lambda col: ~col.str.match(hex_pattern, na=False))\n\n# Get rows with any invalid entries\ninvalid_rows = df_6[mask.any(axis=1)]\n\nprint(\"Rows with non-hex values in DATA columns:\")\nprint(invalid_rows if not invalid_rows.empty else \"No non-hex values found\")","metadata":{"execution":{"iopub.status.busy":"2025-03-05T15:13:56.261398Z","iopub.execute_input":"2025-03-05T15:13:56.261782Z","iopub.status.idle":"2025-03-05T15:14:09.423724Z","shell.execute_reply.started":"2025-03-05T15:13:56.261747Z","shell.execute_reply":"2025-03-05T15:14:09.422653Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_7 = df_6.copy()\n# Function to convert hex to decimal\ndef hex_to_int(hex_str: str) -> int:\n    try:\n        return int(str(hex_str).strip(), 16)  # Convert hex to int\n    except ValueError:\n        return np.nan \n\n# Convert all DATA columns\nfor col in df_7.columns[1:-1]:  # Exclude 'Flag' column\n    df_7[col] = df_7[col].apply(hex_to_int)\n\ndf_7.head()","metadata":{"execution":{"iopub.status.busy":"2025-03-05T15:14:09.424707Z","iopub.execute_input":"2025-03-05T15:14:09.425085Z","iopub.status.idle":"2025-03-05T15:14:29.385250Z","shell.execute_reply.started":"2025-03-05T15:14:09.425057Z","shell.execute_reply":"2025-03-05T15:14:29.384265Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_8 = df_7.copy()","metadata":{"execution":{"iopub.status.busy":"2025-03-05T15:14:29.386206Z","iopub.execute_input":"2025-03-05T15:14:29.386526Z","iopub.status.idle":"2025-03-05T15:14:29.800960Z","shell.execute_reply.started":"2025-03-05T15:14:29.386502Z","shell.execute_reply":"2025-03-05T15:14:29.799856Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_8[\"Flag\"] = df_8[\"Flag\"].map({\"R\": 0, \"T\": 1})\ndf_8.head()","metadata":{"execution":{"iopub.status.busy":"2025-03-05T15:14:29.802007Z","iopub.execute_input":"2025-03-05T15:14:29.802289Z","iopub.status.idle":"2025-03-05T15:14:30.020882Z","shell.execute_reply.started":"2025-03-05T15:14:29.802265Z","shell.execute_reply":"2025-03-05T15:14:30.019846Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_8[\"Flag\"].unique()","metadata":{"execution":{"iopub.status.busy":"2025-03-05T15:14:30.021854Z","iopub.execute_input":"2025-03-05T15:14:30.022116Z","iopub.status.idle":"2025-03-05T15:14:30.048639Z","shell.execute_reply.started":"2025-03-05T15:14:30.022093Z","shell.execute_reply":"2025-03-05T15:14:30.047769Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_8.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2025-03-05T15:14:30.049416Z","iopub.execute_input":"2025-03-05T15:14:30.049687Z","iopub.status.idle":"2025-03-05T15:14:30.115379Z","shell.execute_reply.started":"2025-03-05T15:14:30.049664Z","shell.execute_reply":"2025-03-05T15:14:30.114579Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_8.info()","metadata":{"execution":{"iopub.status.busy":"2025-03-05T15:14:30.116255Z","iopub.execute_input":"2025-03-05T15:14:30.116512Z","iopub.status.idle":"2025-03-05T15:14:30.130265Z","shell.execute_reply.started":"2025-03-05T15:14:30.116491Z","shell.execute_reply":"2025-03-05T15:14:30.128947Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_8.describe()","metadata":{"execution":{"iopub.status.busy":"2025-03-05T15:14:30.131402Z","iopub.execute_input":"2025-03-05T15:14:30.131819Z","iopub.status.idle":"2025-03-05T15:14:31.521367Z","shell.execute_reply.started":"2025-03-05T15:14:30.131780Z","shell.execute_reply":"2025-03-05T15:14:31.520364Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Exclude the 'Flag' column before calculating correlation\ncorrelation_matrix = df_8.drop(columns=['Timestamp', 'CAN ID', 'Flag']).corr()\ncorrelation_matrix","metadata":{"execution":{"iopub.status.busy":"2025-03-05T15:14:31.522401Z","iopub.execute_input":"2025-03-05T15:14:31.522716Z","iopub.status.idle":"2025-03-05T15:14:32.512652Z","shell.execute_reply.started":"2025-03-05T15:14:31.522690Z","shell.execute_reply":"2025-03-05T15:14:32.511794Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\n# Assuming 'correlation_matrix' is already computed\nfig, ax = plt.subplots(figsize=(8, 6))  # Set fixed width (10) and height (8)\n\n# Plot the correlation matrix as a heatmap\nsns.heatmap(correlation_matrix, annot=True, fmt='.2f', linewidths=0.5, ax=ax)\n\n# Save the plot as a PNG image with a fixed size\nplt.tight_layout()  # Ensures proper layout\nplt.savefig(\"correlation_matrix.pdf\", format=\"pdf\", bbox_inches='tight')\n\n\n# Show the plot\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2025-03-05T15:14:32.513694Z","iopub.execute_input":"2025-03-05T15:14:32.513997Z","iopub.status.idle":"2025-03-05T15:14:34.104720Z","shell.execute_reply.started":"2025-03-05T15:14:32.513952Z","shell.execute_reply":"2025-03-05T15:14:34.103672Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_9 = df_8.copy()\ndf_9.head()","metadata":{"execution":{"iopub.status.busy":"2025-03-05T15:14:34.105740Z","iopub.execute_input":"2025-03-05T15:14:34.106375Z","iopub.status.idle":"2025-03-05T15:14:34.443133Z","shell.execute_reply.started":"2025-03-05T15:14:34.106346Z","shell.execute_reply":"2025-03-05T15:14:34.442184Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Realistic Scenario with no CAN ID included\n\n## Algorithm Selection XGB","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport xgboost as xgb\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, roc_curve, auc\n\n# Load data\ndf = df_9.drop(columns=['Timestamp']).copy()\n\n# 1. Preprocessing\n# Convert CAN ID to numerical (already done as 0 for attacks)\ndf['CAN ID'] = df['CAN ID'].astype('int64')\n\n# 2. Define features and target variable\nX = df.drop(['Flag', 'CAN ID'], axis=1)  # Remove the leakage feature\ny = df['Flag']\n\n# 3. Split data with stratification\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, \n    test_size=0.2, \n    stratify=y, \n    random_state=42\n)\n\n# 4. Initialize XGBoost with realistic parameters\nmodel = xgb.XGBClassifier(\n    scale_pos_weight=8,\n    objective='binary:logistic',\n    eval_metric='aucpr',\n    max_depth=6,  # Prevent overfitting\n    subsample=0.8,\n    colsample_bytree=0.8,\n    random_state=42\n)\n\n# 5. Train the model\nmodel.fit(X_train, y_train)\n\n# 6. Evaluate\ny_pred = model.predict(X_test)\ny_proba = model.predict_proba(X_test)[:, 1]\n\n# Print metrics\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\nprint(f\"\\nROC AUC Score: {roc_auc_score(y_test, y_proba):.4f}\")\n\n# 7. Feature Importance\nplt.figure(figsize=(8, 6))\nxgb.plot_importance(model, ax=plt.gca())\nplt.tight_layout()\nplt.savefig(os.path.join(\"feature_importance_1.pdf\"), format=\"pdf\", bbox_inches='tight')\nplt.show()\n# 1. Plot Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.tight_layout()\nplt.savefig(\"confusion_matrix_1.pdf\", format=\"pdf\", bbox_inches='tight')\nplt.show()\n\n# 2. Plot ROC Curve\nfpr, tpr, thresholds = roc_curve(y_test, y_proba)\nroc_auc = auc(fpr, tpr)\n\nplt.figure(figsize=(8, 6))\nplt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.4f})')\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc=\"lower right\")\nplt.tight_layout()\nplt.savefig(\"roc_curve_1.pdf\", format=\"pdf\", bbox_inches='tight')\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2025-03-05T15:14:34.444304Z","iopub.execute_input":"2025-03-05T15:14:34.444701Z","iopub.status.idle":"2025-03-05T15:14:48.563519Z","shell.execute_reply.started":"2025-03-05T15:14:34.444667Z","shell.execute_reply":"2025-03-05T15:14:48.562478Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##  Advanced Feature Engineering","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve\nimport xgboost as xgb\n\n# Load dataset\ndf = df_9.drop(columns=['Timestamp']).copy()\nprint(df.columns)\n\n# Ensure numeric conversion\nfor col in ['DATA0', 'DATA1', 'DATA5', 'DATA7']:\n    df[col] = pd.to_numeric(df[col], errors='coerce')\n\n# Drop NaN values if necessary\ndf = df.dropna(subset=['DATA0', 'DATA1', 'DATA5', 'DATA7', 'Flag'])\n\n# Define feature columns and target\nfeatures = ['DATA0', 'DATA1', 'DATA5', 'DATA7']\nX = df[features]\ny = df['Flag']  # Target: 1 = Attack, 0 = Normal\n\n# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train XGBoost model\nmodel = xgb.XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.1, eval_metric=\"logloss\")\nmodel.fit(X_train, y_train)\n\n# Predictions\ny_pred = model.predict(X_test)\ny_proba = model.predict_proba(X_test)[:, 1]  # Probability scores\n\n# Performance Metrics\nprint(classification_report(y_test, y_pred))\nroc_auc = roc_auc_score(y_test, y_proba)\nprint(f\"ROC AUC Score: {roc_auc:.4f}\")\n\n# Precision-Recall Curve & Optimal Threshold\n# precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n# target_recall = 0.95\n# idx = np.argmax(recall >= target_recall)\n# optimal_threshold = thresholds[idx]\n# print(f\"Optimal Decision Threshold: {optimal_threshold:.2f}\")\n\n# best_idx = np.argmax(precision * recall)  # F1-score based tuning\n# best_threshold = thresholds[best_idx]\n# print(f\"New Optimal Threshold: {best_threshold:.2f}\")\n\n\n# Function to plot distributions\ndef plot_distribution(feature):\n    plt.figure(figsize=(8, 5))\n    sns.histplot(df[df['Flag'] == 0][feature], label='Normal', color='blue', kde=True, alpha=0.6)\n    sns.histplot(df[df['Flag'] == 1][feature], label='Attack', color='red', kde=True, alpha=0.6)\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(f\"{feature}_distribution.pdf\", format=\"pdf\", bbox_inches='tight')\n    plt.show()\n\n# Plot distributions separately\nfor feature in ['DATA0', 'DATA1']:\n    plot_distribution(feature)\n\n# Feature Engineering (Bitwise & Arithmetic Transformations)\ndf['DATA01_XOR'] = df['DATA0'] ^ df['DATA1']\ndf['DATA01_SUM'] = df['DATA0'] + df['DATA1']\ndf['DATA57_XOR'] = df['DATA5'] ^ df['DATA7']\n\nprint(df[['DATA01_XOR', 'DATA01_SUM', 'DATA57_XOR']].describe())\n\n# Train again with engineered features\nX_new = df[['DATA0', 'DATA1', 'DATA5', 'DATA7', 'DATA01_XOR', 'DATA01_SUM', 'DATA57_XOR']]\nX_train_new, X_test_new, y_train, y_test = train_test_split(X_new, y, test_size=0.2, random_state=42)\nmodel.fit(X_train_new, y_train)\n\n# Evaluate again\ny_pred_new = model.predict(X_test_new)\nprint(classification_report(y_test, y_pred_new))\n\n# Compute confusion matrix\ncm = confusion_matrix(y_test, y_pred)\n\n# Plot the confusion matrix as a heatmap\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Normal\", \"Attack\"], yticklabels=[\"Normal\", \"Attack\"])\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\nplt.tight_layout()\nplt.savefig(\"confusion_matrix_2.pdf\", format=\"pdf\", bbox_inches='tight')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2025-03-05T15:14:48.564637Z","iopub.execute_input":"2025-03-05T15:14:48.564931Z","iopub.status.idle":"2025-03-05T15:15:42.459343Z","shell.execute_reply.started":"2025-03-05T15:14:48.564906Z","shell.execute_reply":"2025-03-05T15:15:42.458198Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Initial Model Confusion Matrix\ncm_initial = confusion_matrix(y_test, y_pred)\n\n# Plot Initial Confusion Matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm_initial, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal', 'Attack'], yticklabels=['Normal', 'Attack'])\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.tight_layout()\nplt.savefig(os.path.join(\"confusion_matrix_initial.pdf\"), format=\"pdf\", bbox_inches='tight')\nplt.show()\n\n# Retrained Model Confusion Matrix\ncm_retrained = confusion_matrix(y_test, y_pred_new)\n\n# Plot Retrained Confusion Matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm_retrained, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal', 'Attack'], yticklabels=['Normal', 'Attack'])\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.tight_layout()\nplt.savefig(os.path.join(\"confusion_matrix_retrained.pdf\"), format=\"pdf\", bbox_inches='tight')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T15:15:42.460342Z","iopub.execute_input":"2025-03-05T15:15:42.460714Z","iopub.status.idle":"2025-03-05T15:15:43.438050Z","shell.execute_reply.started":"2025-03-05T15:15:42.460687Z","shell.execute_reply":"2025-03-05T15:15:43.436949Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_9.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T15:15:43.439018Z","iopub.execute_input":"2025-03-05T15:15:43.439282Z","iopub.status.idle":"2025-03-05T15:15:43.452168Z","shell.execute_reply.started":"2025-03-05T15:15:43.439259Z","shell.execute_reply":"2025-03-05T15:15:43.451162Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Temporal Features","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import StratifiedKFold\nimport xgboost as xgb\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score, roc_curve\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom imblearn.over_sampling import SMOTE\n\n\n# Load data\ndf = df_9.copy()\ndf['Timestamp'] = pd.to_datetime(df['Timestamp'], unit='s')\ndf = df.sort_values('Timestamp').reset_index(drop=True)\ndf.set_index('Timestamp', inplace=True)\n\n# Feature Engineering\ndf['Global_Time_Delta'] = df.index.to_series().diff().dt.total_seconds().fillna(0)\ndf['Rolling_Count_1ms'] = df.rolling('1ms').count()['CAN ID']\ndf['Rolling_Count_10ms'] = df.rolling('10ms').count()['CAN ID']\ndf['Rolling_Count_1ms'] = df.rolling('0.3ms').count()['CAN ID']\ndf['Hour'] = df.index.hour\ndf['Time_Since_First_Message'] = (df.index - df.index.min()).total_seconds()\n\n# Prepare features\nX = df.drop(['Flag', 'CAN ID'], axis=1)\ny = df['Flag']\n\n# Apply SMOTE\nsmote = SMOTE(sampling_strategy='auto', random_state=42)\nX_res, y_res = smote.fit_resample(X, y)\n\n# Initialize XGBoost\nmodel = xgb.XGBClassifier(\n    scale_pos_weight=10, \n    objective='binary:logistic',\n    eval_metric='aucpr',\n    max_depth=6,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    random_state=42\n)\n\n# Stratified K-Fold\nkf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n# Metrics storage\nroc_auc_scores, accuracies, classification_reports, confusion_matrices = [], [], [], []\nall_fpr, all_tpr = [], []\n\n# Cross-validation loop\nfor train_index, test_index in kf.split(X_res, y_res):\n    X_train, X_test = X_res.iloc[train_index], X_res.iloc[test_index]\n    y_train, y_test = y_res.iloc[train_index], y_res.iloc[test_index]\n\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    y_proba = model.predict_proba(X_test)[:, 1]\n\n    accuracies.append(accuracy_score(y_test, y_pred))\n    roc_auc_scores.append(roc_auc_score(y_test, y_proba))\n    classification_reports.append(classification_report(y_test, y_pred))\n    confusion_matrices.append(confusion_matrix(y_test, y_pred))\n\n    # Compute ROC curve\n    fpr, tpr, _ = roc_curve(y_test, y_proba)\n    all_fpr.append(fpr)\n    all_tpr.append(tpr)\n\n# Compute final averages\navg_accuracy = np.mean(accuracies)\navg_roc_auc = np.mean(roc_auc_scores)\navg_conf_matrix = np.sum(confusion_matrices, axis=0).astype(int)\n\nprint(f\"Average Accuracy: {avg_accuracy:.4f}\")\nprint(f\"Average ROC AUC Score: {avg_roc_auc:.4f}\")\nprint(f\"\\nAverage Confusion Matrix:\\n {avg_conf_matrix}\")\nprint(\"\\nClassification Report (Example Fold):\\n\", classification_reports[0])\n\n# Feature Importance\nimportances = model.get_booster().get_score(importance_type='gain')\nnormalized_importances = {k: v / sum(importances.values()) for k, v in importances.items()}\nfeature_importance_df = pd.DataFrame(list(normalized_importances.items()), columns=['Feature', 'Importance'])\nfeature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n\n# Plot Feature Importance\nplt.figure(figsize=(10, 6))\nxgb.plot_importance(model, importance_type='gain', ax=plt.gca())\nplt.tight_layout()\nplt.savefig(os.path.join(\"feature_importance_3.pdf\"), format=\"pdf\", bbox_inches='tight')\nplt.show()\n\n# Heatmap of Feature Importance\nplt.figure(figsize=(10, 6))\nsns.heatmap(feature_importance_df.set_index('Feature').T, annot=True, cmap='coolwarm', fmt='.3f')\nplt.tight_layout()\nplt.savefig(\"feature_importance_heatmap_3.pdf\", format=\"pdf\", bbox_inches='tight')\nplt.show()\n\n# Average ROC Curve\nplt.figure(figsize=(8, 6))\nfor fpr, tpr in zip(all_fpr, all_tpr):\n    plt.plot(fpr, tpr, alpha=0.3)  # Plot all folds\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.tight_layout()\nplt.savefig(os.path.join(\"roc_curve_3.pdf\"), format=\"pdf\", bbox_inches='tight')\nplt.show()\n\n# Confusion Matrix Heatmap\nplt.figure(figsize=(8, 6))\nsns.heatmap(avg_conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal', 'GEAR Attack'], yticklabels=['Normal', 'GEAR Attack'])\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.tight_layout()\nplt.savefig(os.path.join(\"confusion_matrix_3.pdf\"), format=\"pdf\", bbox_inches='tight')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2025-03-05T15:15:43.453529Z","iopub.execute_input":"2025-03-05T15:15:43.453901Z","iopub.status.idle":"2025-03-05T15:18:43.687815Z","shell.execute_reply.started":"2025-03-05T15:15:43.453875Z","shell.execute_reply":"2025-03-05T15:18:43.686667Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Updated Confusion Matrix:\n```\ncm = [[605815   9834]\n      [    72 615578]]\n```\n\n### Explanation:\n- **True Positives (TP)**: The number of instances correctly predicted as **Class 1** (attack).\n  - **615578** (bottom-right cell)\n  \n- **False Positives (FP)**: The number of instances incorrectly predicted as **Class 1** when they are actually **Class 0** (normal).\n  - **9834** (top-right cell)\n\n- **True Negatives (TN)**: The number of instances correctly predicted as **Class 0** (normal).\n  - **605815** (top-left cell)\n\n- **False Negatives (FN)**: The number of instances incorrectly predicted as **Class 0** when they are actually **Class 1**.\n  - **72** (bottom-left cell)\n\n### Now, let's compute some key metrics:\n\n1. **Accuracy**: The overall percentage of correct predictions.\n   \\[\n   \\text{Accuracy} = \\frac{TP + TN}{TP + FP + TN + FN}\n   \\]\n   \\[\n   \\text{Accuracy} = \\frac{615578 + 605815}{615578 + 9834 + 605815 + 72} = \\frac{1227393}{1227399} \\approx 0.99995\n   \\]\n   **Accuracy ≈ 99.995%**\n\n2. **Precision for Class 1 (attack)**: The percentage of predicted positive instances (Class 1) that are actually positive.\n   \\[\n   \\text{Precision (Class 1)} = \\frac{TP}{TP + FP} = \\frac{615578}{615578 + 9834} \\approx 0.983\n   \\]\n   **Precision (Class 1) ≈ 98.3%**\n\n3. **Recall for Class 1 (attack)**: The percentage of actual positive instances (Class 1) that were correctly identified.\n   \\[\n   \\text{Recall (Class 1)} = \\frac{TP}{TP + FN} = \\frac{615578}{615578 + 72} \\approx 0.99988\n   \\]\n   **Recall (Class 1) ≈ 99.99%**\n\n4. **F1 Score for Class 1**: The harmonic mean of precision and recall.\n   \\[\n   \\text{F1 Score (Class 1)} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}} \\approx 2 \\times \\frac{0.983 \\times 0.99988}{0.983 + 0.99988} \\approx 0.991\n   \\]\n   **F1 Score (Class 1) ≈ 99.1%**\n\n5. **Precision for Class 0 (normal)**: The percentage of predicted negative instances (Class 0) that are actually negative.\n   \\[\n   \\text{Precision (Class 0)} = \\frac{TN}{TN + FN} = \\frac{605815}{605815 + 72} \\approx 0.99988\n   \\]\n   **Precision (Class 0) ≈ 99.99%**\n\n6. **Recall for Class 0 (normal)**: The percentage of actual negative instances (Class 0) that were correctly identified.\n   \\[\n   \\text{Recall (Class 0)} = \\frac{TN}{TN + FP} = \\frac{605815}{605815 + 9834} \\approx 0.984\n   \\]\n   **Recall (Class 0) ≈ 98.4%**\n\n7. **F1 Score for Class 0**: The harmonic mean of precision and recall for Class 0.\n   \\[\n   \\text{F1 Score (Class 0)} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}} \\approx 2 \\times \\frac{0.99988 \\times 0.984}{0.99988 + 0.984} \\approx 0.992\n   \\]\n   **F1 Score (Class 0) ≈ 99.2%**\n\n### Conclusion:\n- **Accuracy**: 99.995%, which suggests that the model is correct nearly 100% of the time.\n- **For Class 1 (attack)**: The model performs very well with a high **precision** (98.3%) and **recall** (99.99%), making it excellent at detecting **attacks**.\n- **For Class 0 (normal)**: The model also performs excellently for **normal** instances with a **precision** of 99.99% and **recall** of 98.4%.\n\nThe model appears to be performing very well overall, especially for both classes. The **attack class** (Class 1) has very few false negatives, and the **normal class** (Class 0) has very few false positives. However, you may want to look into **class imbalance**, since the numbers of instances of Class 1 and Class 0 may be quite different. But for this case, the model is performing well in distinguishing both classes.","metadata":{}},{"cell_type":"markdown","source":"# Algorithm RF\n","metadata":{}},{"cell_type":"markdown","source":"## Without SMOTE","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\n\n# Load data\ndf = df_9.copy()\n\n# 1. Preprocessing\n# Convert CAN ID to categorical (important for tree models)\ndf['CAN ID'] = df['CAN ID'].astype('category')\n\n# 2. Split data\nX = df.drop('Flag', axis=1)\ny = df['Flag']\n\n# Stratified split to maintain class balance\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, \n    test_size=0.2, \n    stratify=y,\n    random_state=42\n)\n\n# 3. Initialize Random Forest with class weighting\nrf = RandomForestClassifier(\n    n_estimators=100,\n    class_weight='balanced',  # Handles imbalance\n    max_depth=10,             # Prevent overfitting\n    n_jobs=-1,                # Use all cores\n    random_state=42\n)\n\n# 4. Train model\nrf.fit(X_train, y_train)\n\n# 5. Evaluate\ny_pred = rf.predict(X_test)\ny_proba = rf.predict_proba(X_test)[:,1]\n\n# Evaluate model performance\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n\nprint(f\"\\nROC AUC Score: {roc_auc_score(y_test, y_proba):.4f}\")\n\n# 6. Feature Importance\nfeatures = X.columns\nimportances = rf.feature_importances_\nstd = np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)\n\n# Create DataFrame\nfi_df = pd.DataFrame({'Feature': features, 'Importance': importances, 'Std': std})\nfi_df = fi_df.sort_values('Importance', ascending=False)\n\n# Plot Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.tight_layout()\nplt.savefig(os.path.join(\"confusion_matrix_rf_1.pdf\"), format=\"pdf\", bbox_inches='tight')\nplt.show()\n\n# Plot\nplt.figure(figsize=(10,6))\nplt.bar(fi_df['Feature'], fi_df['Importance'], yerr=fi_df['Std'])\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.savefig(os.path.join(\"feature_imp_rf_1.pdf\"), format=\"pdf\", bbox_inches='tight')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T15:18:43.688943Z","iopub.execute_input":"2025-03-05T15:18:43.689269Z","iopub.status.idle":"2025-03-05T15:19:36.749537Z","shell.execute_reply.started":"2025-03-05T15:18:43.689244Z","shell.execute_reply":"2025-03-05T15:19:36.748471Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Class Weight Tuning","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score\nimport matplotlib.pyplot as plt\n\n# Load data\ndf = df_9.copy()\n\n\n# 2. Split data\nX = df.drop(['Timestamp', 'Flag', 'CAN ID'], axis=1)  # Remove the leakage feature\ny = df['Flag']\n\n# Stratified split to maintain class balance\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, \n    test_size=0.2, \n    stratify=y,\n    random_state=42\n)\n\n# 3. Manually calculate class weights based on the exact class ratio (~5.24:1)\n# ratio = 3_078_250 / 587_521  # approximately 5.24\nratio = 10\nclass_weights = {0: 1, 1: ratio}  # Assign higher weight to minority class\n\n# 4. Initialize Random Forest with manually calculated class weights\nrf = RandomForestClassifier(\n    n_estimators=100,\n    class_weight=class_weights,  # using manual weights instead of 'balanced'\n    max_depth=10,                # Prevent overfitting\n    n_jobs=-1,                   # Use all available cores\n    random_state=42\n)\n\n# 5. Train the model\nrf.fit(X_train, y_train)\n\n# 6. Evaluate the model\ny_pred = rf.predict(X_test)\ny_proba = rf.predict_proba(X_test)[:, 1]\n\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\nprint(f\"\\nROC AUC Score: {roc_auc_score(y_test, y_proba):.4f}\")\n\n# 7. Feature Importance\nfeatures = X.columns\nimportances = rf.feature_importances_\nstd = np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)\n\n# Create DataFrame for feature importances\nfi_df = pd.DataFrame({'Feature': features, 'Importance': importances, 'Std': std})\nfi_df = fi_df.sort_values('Importance', ascending=False)\n\n# Plot Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.tight_layout()\nplt.savefig(os.path.join(\"confusion_matrix_rf_2.pdf\"), format=\"pdf\", bbox_inches='tight')\nplt.show()\n\n# Plot feature importances\nplt.figure(figsize=(10, 6))\nplt.bar(fi_df['Feature'], fi_df['Importance'], yerr=fi_df['Std'])\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.savefig(os.path.join(\"feature_imp_rf.pdf\"), format=\"pdf\", bbox_inches='tight')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T15:19:36.750915Z","iopub.execute_input":"2025-03-05T15:19:36.751261Z","iopub.status.idle":"2025-03-05T15:20:22.624653Z","shell.execute_reply.started":"2025-03-05T15:19:36.751233Z","shell.execute_reply":"2025-03-05T15:20:22.623579Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Threshold Adjustment","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport xgboost as xgb\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score, precision_recall_curve\nimport matplotlib.pyplot as plt\n\n# Load data\ndf = df_9.copy()\n\n\nX = df.drop(['Timestamp', 'Flag', 'CAN ID'], axis=1)  # Remove the leakage feature\ny = df['Flag']\n\n# 3. Split data with stratification to maintain class balance\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, \n    test_size=0.2, \n    stratify=y, \n    random_state=42\n)\n\n# 4. Initialize XGBoost classifier with built-in imbalance handling\nmodel = xgb.XGBClassifier(\n    scale_pos_weight=5.24,      # Directly accounts for the class imbalance ratio\n    objective='binary:logistic',\n    eval_metric='aucpr',        # Optimize for precision-recall AUC\n    use_label_encoder=False,    # Suppress a warning regarding label encoding\n    random_state=42\n)\n\n# 5. Train the model\nmodel.fit(X_train, y_train)\n\n# 6. Get predicted probabilities for the positive class\ny_proba = model.predict_proba(X_test)[:, 1]\n\n# 7. Threshold Adjustment: Optimize decision threshold using precision-recall curve\nprecision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n\n# Compute F1 scores for each threshold; note that thresholds array is one element shorter than precision/recall\nf1_scores = 2 * precision[:-1] * recall[:-1] / (precision[:-1] + recall[:-1] + 1e-8)  # avoid division by zero\nbest_idx = np.argmax(f1_scores)\nbest_threshold = thresholds[best_idx]\nprint(f\"Optimal Threshold (based on maximum F1): {best_threshold:.4f}\")\n\n# Use the optimal threshold to make final predictions\ny_pred = (y_proba >= best_threshold).astype(int)\n\n# 8. Evaluate the model with the adjusted threshold\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\nprint(f\"\\nROC AUC Score: {roc_auc_score(y_test, y_proba):.4f}\")\n\n# Plot Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.tight_layout()\nplt.savefig(os.path.join(\"confusion_matrix_rf_3.pdf\"), format=\"pdf\", bbox_inches='tight')\n\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T15:20:22.625777Z","iopub.execute_input":"2025-03-05T15:20:22.626060Z","iopub.status.idle":"2025-03-05T15:20:34.459848Z","shell.execute_reply.started":"2025-03-05T15:20:22.626036Z","shell.execute_reply":"2025-03-05T15:20:34.458756Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## With SMOTE and KFold","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score, roc_curve\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom imblearn.over_sampling import SMOTE  # Import SMOTE\n\n# Ensure directory exists for saving plots\nimage_dir = \"../images\"\nos.makedirs(image_dir, exist_ok=True)\n\n# Load data\ndf = df_9.copy()\n\n# Prepare Features and Target\nX = df.drop(['Timestamp','Flag', 'CAN ID'], axis=1)  # Remove 'Flag' (target) and 'CAN ID' (identifier)\ny = df['Flag']\n\n# Apply SMOTE\nsmote = SMOTE(sampling_strategy='auto', random_state=42)\n\n# Initialize Random Forest with Class Weighting\nrf = RandomForestClassifier(\n    n_estimators=10,\n    class_weight='balanced',  # Handles imbalance\n    max_depth=10,             # Prevent overfitting\n    n_jobs=-1,                # Use all CPU cores\n    random_state=42\n)\n\n# Stratified K-Fold\nkf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n# Metrics storage\nroc_auc_scores, accuracies, classification_reports, confusion_matrices = [], [], [], []\nall_fpr, all_tpr = [], []\n\n# Cross-validation loop\nfor train_index, test_index in kf.split(X, y):\n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n\n    # Apply SMOTE to the training set only\n    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n\n    # Train the Model on Resampled Data\n    rf.fit(X_train_res, y_train_res)\n\n    # Make predictions\n    y_pred = rf.predict(X_test)\n    y_proba = rf.predict_proba(X_test)[:,1]  # Get probability of the positive class\n\n    # Store performance metrics\n    accuracies.append(accuracy_score(y_test, y_pred))\n    roc_auc_scores.append(roc_auc_score(y_test, y_proba))\n    classification_reports.append(classification_report(y_test, y_pred))\n    confusion_matrices.append(confusion_matrix(y_test, y_pred))\n\n    # Compute ROC curve\n    fpr, tpr, _ = roc_curve(y_test, y_proba)\n    all_fpr.append(fpr)\n    all_tpr.append(tpr)\n\n# Compute final averages\navg_accuracy = np.mean(accuracies)\navg_roc_auc = np.mean(roc_auc_scores)\navg_conf_matrix = np.sum(confusion_matrices, axis=0).astype(int)\n\nprint(f\"Average Accuracy: {avg_accuracy:.4f}\")\nprint(f\"Average ROC AUC Score: {avg_roc_auc:.4f}\")\nprint(f\"\\nAverage Confusion Matrix:\\n {avg_conf_matrix}\")\nprint(\"\\nClassification Report (Example Fold):\\n\", classification_reports[0])\n\n# Average ROC Curve\nplt.figure(figsize=(8, 6))\nfor fpr, tpr in zip(all_fpr, all_tpr):\n    plt.plot(fpr, tpr, alpha=0.3)  # Plot all folds\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title(f'Average ROC Curve (AUC = {avg_roc_auc:.4f})')\nplt.tight_layout()\nplt.savefig(os.path.join(image_dir, \"roc_curve_rf.pdf\"), format=\"pdf\", bbox_inches='tight')\nplt.show()\n\n# Average Confusion Matrix Heatmap\nplt.figure(figsize=(8, 6))\nsns.heatmap(avg_conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal', 'GEAR Attack'], yticklabels=['Normal', 'GEAR Attack'])\nplt.title('Average Confusion Matrix (Random Forest)')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.tight_layout()\nplt.savefig(os.path.join(image_dir, \"confusion_matrix_rf.pdf\"), format=\"pdf\", bbox_inches='tight')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T15:20:34.460990Z","iopub.execute_input":"2025-03-05T15:20:34.461390Z","execution_failed":"2025-03-05T16:00:21.781Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## SMOTE but no KFold","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score\nfrom imblearn.over_sampling import SMOTE  # Import SMOTE\nimport matplotlib.pyplot as plt\n\n# Load data\ndf = df_9.copy()\n\n# 1. Prepare Features and Target\nX = df.drop(['Timestamp','Flag', 'CAN ID'], axis=1)  # Remove 'Timestamp' 'Flag' (target) and 'CAN ID' (identifier)\ny = df['Flag']\n\n# 2. Stratified Train-Test Split\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, \n    test_size=0.2, \n    stratify=y,\n    random_state=42\n)\n\n# 3. Apply SMOTE for Oversampling\nsmote = SMOTE(sampling_strategy='auto', random_state=42)\nX_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n\n# Print class distribution before and after SMOTE\nprint(f\"Before SMOTE: {np.bincount(y_train)}\")\nprint(f\"After SMOTE: {np.bincount(y_train_res)}\")\n\n# 4. Initialize Random Forest with Class Weighting\nrf = RandomForestClassifier(\n    n_estimators=20,\n    class_weight='balanced',  # Handles imbalance\n    max_depth=10,             # Prevent overfitting\n    n_jobs=-1,                # Use all CPU cores\n    random_state=42\n)\n\n# 5. Train the Model on Resampled Data\nrf.fit(X_train_res, y_train_res)\n\n# 6. Evaluate on Test Set\ny_pred = rf.predict(X_test)\ny_proba = rf.predict_proba(X_test)[:,1]  # Get probability of the positive class\n\n# Performance Metrics\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\nprint(f\"\\nROC AUC Score: {roc_auc_score(y_test, y_proba):.4f}\")\n\n\n\n# Plot Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.tight_layout()\nplt.savefig(os.path.join(\"confusion_matrix_rf_2.pdf\"), format=\"pdf\", bbox_inches='tight')\nplt.show()\n\n\n# Before SMOTE: [2462599  470017]\n# After SMOTE: [2462599 2462599]\n# Accuracy: 0.9766351953341317\n# Confusion Matrix:\n#  [[598520  17130]\n#  [     0 117504]]\n# Classification Report:\n#                precision    recall  f1-score   support\n\n#            0       1.00      0.97      0.99    615650\n#            1       0.87      1.00      0.93    117504\n\n#     accuracy                           0.98    733154\n#    macro avg       0.94      0.99      0.96    733154\n# weighted avg       0.98      0.98      0.98    733154\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-05T16:00:21.918Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# SVM Model","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Load data\ndf = df_9.copy()\n\n# 1. Prepare Features and Target\nX = df.drop(['Timestamp', 'Flag', 'CAN ID'], axis=1)  # Remove 'Flag' (target) and 'CAN ID' (identifier)\ny = df['Flag']\n\n# 2. Stratified Train-Test Split\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, \n    test_size=0.2, \n    stratify=y,\n    random_state=42\n)\n\n# Print class distribution before splitting\nprint(f\"Class distribution in training set: {np.bincount(y_train)}\")\n\n# 3. Initialize SVM with Class Weighting\nsvm = SVC(\n    kernel='rbf',            # 'linear' can be used for high-dimensional sparse data\n    class_weight='balanced',  # Handle class imbalance\n    probability=True,         # Enable probability estimates (needed for ROC AUC)\n    random_state=42\n)\n\n# 4. Train the Model\nsvm.fit(X_train, y_train)\n\n# 5. Evaluate on Test Set\ny_pred = svm.predict(X_test)\ny_proba = svm.predict_proba(X_test)[:, 1]  # Get probability of the positive class\n\n# Performance Metrics\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\nprint(f\"\\nROC AUC Score: {roc_auc_score(y_test, y_proba):.4f}\")\n\n# Plot Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.tight_layout()\nplt.savefig(os.path.join(\"confusion_matrix_svm_1.pdf\"), format=\"pdf\", bbox_inches='tight')\nplt.show()\n\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-05T16:00:21.918Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}