{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10647102,"sourceType":"datasetVersion","datasetId":6592386}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom imblearn.over_sampling import SMOTE\nimport joblib\nimport re\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true,"execution":{"iopub.status.busy":"2025-04-10T01:35:27.270937Z","iopub.execute_input":"2025-04-10T01:35:27.271348Z","iopub.status.idle":"2025-04-10T01:35:29.480572Z","shell.execute_reply.started":"2025-04-10T01:35:27.271316Z","shell.execute_reply":"2025-04-10T01:35:29.479519Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"dos_df = pd.read_csv('/kaggle/input/car-hacking-dataset/DoS_dataset.csv')\n\ndos_df.columns = ['Timestamp', 'CAN ID', 'DLC', 'DATA0', 'DATA1', 'DATA2', 'DATA3', 'DATA4', 'DATA5', 'DATA6', 'DATA7', 'Flag']\ndos_df.head()","metadata":{"execution":{"iopub.status.busy":"2025-04-10T01:35:29.481868Z","iopub.execute_input":"2025-04-10T01:35:29.482456Z","iopub.status.idle":"2025-04-10T01:35:36.547061Z","shell.execute_reply.started":"2025-04-10T01:35:29.482415Z","shell.execute_reply":"2025-04-10T01:35:36.545924Z"},"trusted":true},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"      Timestamp CAN ID  DLC DATA0 DATA1 DATA2 DATA3 DATA4 DATA5 DATA6 DATA7  \\\n0  1.478198e+09   018f    8    fe    5b    00    00    00    3c    00    00   \n1  1.478198e+09   0260    8    19    21    22    30    08    8e    6d    3a   \n2  1.478198e+09   02a0    8    64    00    9a    1d    97    02    bd    00   \n3  1.478198e+09   0329    8    40    bb    7f    14    11    20    00    14   \n4  1.478198e+09   0545    8    d8    00    00    8a    00    00    00    00   \n\n  Flag  \n0    R  \n1    R  \n2    R  \n3    R  \n4    R  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Timestamp</th>\n      <th>CAN ID</th>\n      <th>DLC</th>\n      <th>DATA0</th>\n      <th>DATA1</th>\n      <th>DATA2</th>\n      <th>DATA3</th>\n      <th>DATA4</th>\n      <th>DATA5</th>\n      <th>DATA6</th>\n      <th>DATA7</th>\n      <th>Flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.478198e+09</td>\n      <td>018f</td>\n      <td>8</td>\n      <td>fe</td>\n      <td>5b</td>\n      <td>00</td>\n      <td>00</td>\n      <td>00</td>\n      <td>3c</td>\n      <td>00</td>\n      <td>00</td>\n      <td>R</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.478198e+09</td>\n      <td>0260</td>\n      <td>8</td>\n      <td>19</td>\n      <td>21</td>\n      <td>22</td>\n      <td>30</td>\n      <td>08</td>\n      <td>8e</td>\n      <td>6d</td>\n      <td>3a</td>\n      <td>R</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.478198e+09</td>\n      <td>02a0</td>\n      <td>8</td>\n      <td>64</td>\n      <td>00</td>\n      <td>9a</td>\n      <td>1d</td>\n      <td>97</td>\n      <td>02</td>\n      <td>bd</td>\n      <td>00</td>\n      <td>R</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.478198e+09</td>\n      <td>0329</td>\n      <td>8</td>\n      <td>40</td>\n      <td>bb</td>\n      <td>7f</td>\n      <td>14</td>\n      <td>11</td>\n      <td>20</td>\n      <td>00</td>\n      <td>14</td>\n      <td>R</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.478198e+09</td>\n      <td>0545</td>\n      <td>8</td>\n      <td>d8</td>\n      <td>00</td>\n      <td>00</td>\n      <td>8a</td>\n      <td>00</td>\n      <td>00</td>\n      <td>00</td>\n      <td>00</td>\n      <td>R</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"dos_df.nunique()","metadata":{"execution":{"iopub.status.busy":"2025-04-10T01:35:36.548805Z","iopub.execute_input":"2025-04-10T01:35:36.549202Z","iopub.status.idle":"2025-04-10T01:35:38.956560Z","shell.execute_reply.started":"2025-04-10T01:35:36.549162Z","shell.execute_reply":"2025-04-10T01:35:38.955654Z"},"trusted":true},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"Timestamp    3665770\nCAN ID            27\nDLC                2\nDATA0            108\nDATA1             71\nDATA2             76\nDATA3             26\nDATA4            190\nDATA5            256\nDATA6             75\nDATA7            256\nFlag               2\ndtype: int64"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"df_2 = dos_df.copy()","metadata":{"execution":{"iopub.status.busy":"2025-04-10T01:35:38.957711Z","iopub.execute_input":"2025-04-10T01:35:38.957966Z","iopub.status.idle":"2025-04-10T01:35:39.267015Z","shell.execute_reply.started":"2025-04-10T01:35:38.957945Z","shell.execute_reply":"2025-04-10T01:35:39.266154Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"missing_values = df_2.isnull().sum()\nmissing_values","metadata":{"execution":{"iopub.status.busy":"2025-04-10T01:35:39.268119Z","iopub.execute_input":"2025-04-10T01:35:39.268526Z","iopub.status.idle":"2025-04-10T01:35:41.049826Z","shell.execute_reply.started":"2025-04-10T01:35:39.268488Z","shell.execute_reply":"2025-04-10T01:35:41.048784Z"},"trusted":true},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Timestamp        0\nCAN ID           0\nDLC              0\nDATA0            0\nDATA1            0\nDATA2            0\nDATA3        31188\nDATA4        31188\nDATA5        31188\nDATA6        31188\nDATA7        31188\nFlag         31188\ndtype: int64"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"df_dlc_is_2 = df_2[df_2[\"DLC\"] == 2].copy()\ndf_dlc_is_2.head(), df_dlc_is_2.shape","metadata":{"execution":{"iopub.status.busy":"2025-04-10T01:35:41.050899Z","iopub.execute_input":"2025-04-10T01:35:41.051267Z","iopub.status.idle":"2025-04-10T01:35:41.109431Z","shell.execute_reply.started":"2025-04-10T01:35:41.051238Z","shell.execute_reply":"2025-04-10T01:35:41.108437Z"},"trusted":true},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(        Timestamp CAN ID  DLC DATA0 DATA1 DATA2 DATA3 DATA4 DATA5 DATA6 DATA7  \\\n 35   1.478198e+09   05f0    2    01    00     R   NaN   NaN   NaN   NaN   NaN   \n 134  1.478198e+09   05f0    2    01    00     R   NaN   NaN   NaN   NaN   NaN   \n 226  1.478198e+09   05f0    2    01    00     R   NaN   NaN   NaN   NaN   NaN   \n 319  1.478198e+09   05f0    2    01    00     R   NaN   NaN   NaN   NaN   NaN   \n 411  1.478198e+09   05f0    2    01    00     R   NaN   NaN   NaN   NaN   NaN   \n \n     Flag  \n 35   NaN  \n 134  NaN  \n 226  NaN  \n 319  NaN  \n 411  NaN  ,\n (31188, 12))"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"df_d2_nan = df_2[df_2[\"DATA2\"] == 'R'].copy()\ndf_d2_nan.head(), df_d2_nan.shape","metadata":{"execution":{"iopub.status.busy":"2025-04-10T01:35:41.111584Z","iopub.execute_input":"2025-04-10T01:35:41.111857Z","iopub.status.idle":"2025-04-10T01:35:41.418194Z","shell.execute_reply.started":"2025-04-10T01:35:41.111834Z","shell.execute_reply":"2025-04-10T01:35:41.417196Z"},"trusted":true},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(        Timestamp CAN ID  DLC DATA0 DATA1 DATA2 DATA3 DATA4 DATA5 DATA6 DATA7  \\\n 35   1.478198e+09   05f0    2    01    00     R   NaN   NaN   NaN   NaN   NaN   \n 134  1.478198e+09   05f0    2    01    00     R   NaN   NaN   NaN   NaN   NaN   \n 226  1.478198e+09   05f0    2    01    00     R   NaN   NaN   NaN   NaN   NaN   \n 319  1.478198e+09   05f0    2    01    00     R   NaN   NaN   NaN   NaN   NaN   \n 411  1.478198e+09   05f0    2    01    00     R   NaN   NaN   NaN   NaN   NaN   \n \n     Flag  \n 35   NaN  \n 134  NaN  \n 226  NaN  \n 319  NaN  \n 411  NaN  ,\n (31188, 12))"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"df_flag_nan = df_2[(df_2[\"Flag\"] != \"T\") & (df_2[\"Flag\"] != \"R\")]\ndf_flag_nan.head(10), df_flag_nan.shape","metadata":{"execution":{"iopub.status.busy":"2025-04-10T01:35:41.420113Z","iopub.execute_input":"2025-04-10T01:35:41.420496Z","iopub.status.idle":"2025-04-10T01:35:41.977082Z","shell.execute_reply.started":"2025-04-10T01:35:41.420468Z","shell.execute_reply":"2025-04-10T01:35:41.975861Z"},"trusted":true},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(        Timestamp CAN ID  DLC DATA0 DATA1 DATA2 DATA3 DATA4 DATA5 DATA6 DATA7  \\\n 35   1.478198e+09   05f0    2    01    00     R   NaN   NaN   NaN   NaN   NaN   \n 134  1.478198e+09   05f0    2    01    00     R   NaN   NaN   NaN   NaN   NaN   \n 226  1.478198e+09   05f0    2    01    00     R   NaN   NaN   NaN   NaN   NaN   \n 319  1.478198e+09   05f0    2    01    00     R   NaN   NaN   NaN   NaN   NaN   \n 411  1.478198e+09   05f0    2    01    00     R   NaN   NaN   NaN   NaN   NaN   \n 504  1.478198e+09   05f0    2    01    00     R   NaN   NaN   NaN   NaN   NaN   \n 596  1.478198e+09   05f0    2    01    00     R   NaN   NaN   NaN   NaN   NaN   \n 689  1.478198e+09   05f0    2    01    00     R   NaN   NaN   NaN   NaN   NaN   \n 781  1.478198e+09   05f0    2    01    00     R   NaN   NaN   NaN   NaN   NaN   \n 874  1.478198e+09   05f0    2    01    00     R   NaN   NaN   NaN   NaN   NaN   \n \n     Flag  \n 35   NaN  \n 134  NaN  \n 226  NaN  \n 319  NaN  \n 411  NaN  \n 504  NaN  \n 596  NaN  \n 689  NaN  \n 781  NaN  \n 874  NaN  ,\n (31188, 12))"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"df_3 = df_2.copy()","metadata":{"execution":{"iopub.status.busy":"2025-04-10T01:35:41.978104Z","iopub.execute_input":"2025-04-10T01:35:41.978483Z","iopub.status.idle":"2025-04-10T01:35:42.294011Z","shell.execute_reply.started":"2025-04-10T01:35:41.978455Z","shell.execute_reply":"2025-04-10T01:35:42.293181Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# For rows with DLC=2, move 'R' from DATA2 to Flag\nmask = df_3[\"DLC\"] == 2\ndf_3.loc[mask, \"Flag\"] = df_3.loc[mask, \"DATA2\"]  # Copy 'R' to Flag\ndf_3.loc[mask, \"DATA2\"] = np.nan  # Set DATA2 to NaN for DLC=2\n\n\n\n# Verify alignment\nprint(df_3[df_3[\"DLC\"] == 2].head())","metadata":{"execution":{"iopub.status.busy":"2025-04-10T01:35:42.294956Z","iopub.execute_input":"2025-04-10T01:35:42.295261Z","iopub.status.idle":"2025-04-10T01:35:42.425577Z","shell.execute_reply.started":"2025-04-10T01:35:42.295233Z","shell.execute_reply":"2025-04-10T01:35:42.424442Z"},"trusted":true},"outputs":[{"name":"stdout","text":"        Timestamp CAN ID  DLC DATA0 DATA1 DATA2 DATA3 DATA4 DATA5 DATA6 DATA7  \\\n35   1.478198e+09   05f0    2    01    00   NaN   NaN   NaN   NaN   NaN   NaN   \n134  1.478198e+09   05f0    2    01    00   NaN   NaN   NaN   NaN   NaN   NaN   \n226  1.478198e+09   05f0    2    01    00   NaN   NaN   NaN   NaN   NaN   NaN   \n319  1.478198e+09   05f0    2    01    00   NaN   NaN   NaN   NaN   NaN   NaN   \n411  1.478198e+09   05f0    2    01    00   NaN   NaN   NaN   NaN   NaN   NaN   \n\n    Flag  \n35     R  \n134    R  \n226    R  \n319    R  \n411    R  \n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"df_4 = df_3.copy()","metadata":{"execution":{"iopub.status.busy":"2025-04-10T01:35:42.426533Z","iopub.execute_input":"2025-04-10T01:35:42.426850Z","iopub.status.idle":"2025-04-10T01:35:42.764406Z","shell.execute_reply.started":"2025-04-10T01:35:42.426823Z","shell.execute_reply":"2025-04-10T01:35:42.763273Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Fill NaN with hex 00\ndefault_hex = '00'\ndata_columns = ['DATA2', 'DATA3', 'DATA4', 'DATA5', 'DATA6', 'DATA7', 'Flag']\ndf_4[data_columns] = df_4[data_columns].fillna(default_hex)\nprint(df_4[df_4[\"DLC\"] == 2].head()), df_4[df_4[\"DLC\"] == 2].shape","metadata":{"execution":{"iopub.status.busy":"2025-04-10T01:35:42.765568Z","iopub.execute_input":"2025-04-10T01:35:42.765955Z","iopub.status.idle":"2025-04-10T01:35:45.771525Z","shell.execute_reply.started":"2025-04-10T01:35:42.765918Z","shell.execute_reply":"2025-04-10T01:35:45.770649Z"},"trusted":true},"outputs":[{"name":"stdout","text":"        Timestamp CAN ID  DLC DATA0 DATA1 DATA2 DATA3 DATA4 DATA5 DATA6 DATA7  \\\n35   1.478198e+09   05f0    2    01    00    00    00    00    00    00    00   \n134  1.478198e+09   05f0    2    01    00    00    00    00    00    00    00   \n226  1.478198e+09   05f0    2    01    00    00    00    00    00    00    00   \n319  1.478198e+09   05f0    2    01    00    00    00    00    00    00    00   \n411  1.478198e+09   05f0    2    01    00    00    00    00    00    00    00   \n\n    Flag  \n35     R  \n134    R  \n226    R  \n319    R  \n411    R  \n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"(None, (31188, 12))"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"df_4.head(), df_4.shape","metadata":{"execution":{"iopub.status.busy":"2025-04-10T01:35:45.772536Z","iopub.execute_input":"2025-04-10T01:35:45.772924Z","iopub.status.idle":"2025-04-10T01:35:45.783655Z","shell.execute_reply.started":"2025-04-10T01:35:45.772888Z","shell.execute_reply":"2025-04-10T01:35:45.782683Z"},"trusted":true},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(      Timestamp CAN ID  DLC DATA0 DATA1 DATA2 DATA3 DATA4 DATA5 DATA6 DATA7  \\\n 0  1.478198e+09   018f    8    fe    5b    00    00    00    3c    00    00   \n 1  1.478198e+09   0260    8    19    21    22    30    08    8e    6d    3a   \n 2  1.478198e+09   02a0    8    64    00    9a    1d    97    02    bd    00   \n 3  1.478198e+09   0329    8    40    bb    7f    14    11    20    00    14   \n 4  1.478198e+09   0545    8    d8    00    00    8a    00    00    00    00   \n \n   Flag  \n 0    R  \n 1    R  \n 2    R  \n 3    R  \n 4    R  ,\n (3665770, 12))"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"df_4[(df_4[\"Flag\"] != \"T\") & (df_4[\"Flag\"] != \"R\")]\n","metadata":{"execution":{"iopub.status.busy":"2025-04-10T01:35:45.784603Z","iopub.execute_input":"2025-04-10T01:35:45.784881Z","iopub.status.idle":"2025-04-10T01:35:46.322706Z","shell.execute_reply.started":"2025-04-10T01:35:45.784858Z","shell.execute_reply":"2025-04-10T01:35:46.321669Z"},"trusted":true},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"Empty DataFrame\nColumns: [Timestamp, CAN ID, DLC, DATA0, DATA1, DATA2, DATA3, DATA4, DATA5, DATA6, DATA7, Flag]\nIndex: []","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Timestamp</th>\n      <th>CAN ID</th>\n      <th>DLC</th>\n      <th>DATA0</th>\n      <th>DATA1</th>\n      <th>DATA2</th>\n      <th>DATA3</th>\n      <th>DATA4</th>\n      <th>DATA5</th>\n      <th>DATA6</th>\n      <th>DATA7</th>\n      <th>Flag</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"df_4[df_4[\"DATA2\"] == 'R'].head()","metadata":{"execution":{"iopub.status.busy":"2025-04-10T01:35:46.323665Z","iopub.execute_input":"2025-04-10T01:35:46.323952Z","iopub.status.idle":"2025-04-10T01:35:46.602093Z","shell.execute_reply.started":"2025-04-10T01:35:46.323924Z","shell.execute_reply":"2025-04-10T01:35:46.601028Z"},"trusted":true},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"Empty DataFrame\nColumns: [Timestamp, CAN ID, DLC, DATA0, DATA1, DATA2, DATA3, DATA4, DATA5, DATA6, DATA7, Flag]\nIndex: []","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Timestamp</th>\n      <th>CAN ID</th>\n      <th>DLC</th>\n      <th>DATA0</th>\n      <th>DATA1</th>\n      <th>DATA2</th>\n      <th>DATA3</th>\n      <th>DATA4</th>\n      <th>DATA5</th>\n      <th>DATA6</th>\n      <th>DATA7</th>\n      <th>Flag</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"# Drop unnecessary columns\ndf_drop_dlc = df_4.drop([\"DLC\"], axis=1).copy()\ndf_drop_dlc.head()","metadata":{"execution":{"iopub.status.busy":"2025-04-10T01:35:46.603182Z","iopub.execute_input":"2025-04-10T01:35:46.603588Z","iopub.status.idle":"2025-04-10T01:35:48.607434Z","shell.execute_reply.started":"2025-04-10T01:35:46.603551Z","shell.execute_reply":"2025-04-10T01:35:48.606472Z"},"trusted":true},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"      Timestamp CAN ID DATA0 DATA1 DATA2 DATA3 DATA4 DATA5 DATA6 DATA7 Flag\n0  1.478198e+09   018f    fe    5b    00    00    00    3c    00    00    R\n1  1.478198e+09   0260    19    21    22    30    08    8e    6d    3a    R\n2  1.478198e+09   02a0    64    00    9a    1d    97    02    bd    00    R\n3  1.478198e+09   0329    40    bb    7f    14    11    20    00    14    R\n4  1.478198e+09   0545    d8    00    00    8a    00    00    00    00    R","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Timestamp</th>\n      <th>CAN ID</th>\n      <th>DATA0</th>\n      <th>DATA1</th>\n      <th>DATA2</th>\n      <th>DATA3</th>\n      <th>DATA4</th>\n      <th>DATA5</th>\n      <th>DATA6</th>\n      <th>DATA7</th>\n      <th>Flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.478198e+09</td>\n      <td>018f</td>\n      <td>fe</td>\n      <td>5b</td>\n      <td>00</td>\n      <td>00</td>\n      <td>00</td>\n      <td>3c</td>\n      <td>00</td>\n      <td>00</td>\n      <td>R</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.478198e+09</td>\n      <td>0260</td>\n      <td>19</td>\n      <td>21</td>\n      <td>22</td>\n      <td>30</td>\n      <td>08</td>\n      <td>8e</td>\n      <td>6d</td>\n      <td>3a</td>\n      <td>R</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.478198e+09</td>\n      <td>02a0</td>\n      <td>64</td>\n      <td>00</td>\n      <td>9a</td>\n      <td>1d</td>\n      <td>97</td>\n      <td>02</td>\n      <td>bd</td>\n      <td>00</td>\n      <td>R</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.478198e+09</td>\n      <td>0329</td>\n      <td>40</td>\n      <td>bb</td>\n      <td>7f</td>\n      <td>14</td>\n      <td>11</td>\n      <td>20</td>\n      <td>00</td>\n      <td>14</td>\n      <td>R</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.478198e+09</td>\n      <td>0545</td>\n      <td>d8</td>\n      <td>00</td>\n      <td>00</td>\n      <td>8a</td>\n      <td>00</td>\n      <td>00</td>\n      <td>00</td>\n      <td>00</td>\n      <td>R</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"df_drop_dlc.dtypes, df_drop_dlc.shape","metadata":{"execution":{"iopub.status.busy":"2025-04-10T01:35:48.608510Z","iopub.execute_input":"2025-04-10T01:35:48.608894Z","iopub.status.idle":"2025-04-10T01:35:48.616034Z","shell.execute_reply.started":"2025-04-10T01:35:48.608854Z","shell.execute_reply":"2025-04-10T01:35:48.615166Z"},"trusted":true},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"(Timestamp    float64\n CAN ID        object\n DATA0         object\n DATA1         object\n DATA2         object\n DATA3         object\n DATA4         object\n DATA5         object\n DATA6         object\n DATA7         object\n Flag          object\n dtype: object,\n (3665770, 11))"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"df_can_id_0000 = df_drop_dlc[df_drop_dlc[\"CAN ID\"] == \"0000\"]\ndf_can_id_0000.head(), df_can_id_0000.shape","metadata":{"execution":{"iopub.status.busy":"2025-04-10T01:35:48.617153Z","iopub.execute_input":"2025-04-10T01:35:48.617561Z","iopub.status.idle":"2025-04-10T01:35:48.979409Z","shell.execute_reply.started":"2025-04-10T01:35:48.617523Z","shell.execute_reply":"2025-04-10T01:35:48.978517Z"},"trusted":true},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"(         Timestamp CAN ID DATA0 DATA1 DATA2 DATA3 DATA4 DATA5 DATA6 DATA7 Flag\n 1475  1.478198e+09   0000    00    00    00    00    00    00    00    00    T\n 1477  1.478198e+09   0000    00    00    00    00    00    00    00    00    T\n 1479  1.478198e+09   0000    00    00    00    00    00    00    00    00    T\n 1481  1.478198e+09   0000    00    00    00    00    00    00    00    00    T\n 1483  1.478198e+09   0000    00    00    00    00    00    00    00    00    T,\n (587521, 11))"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"df_6 = df_drop_dlc.copy()\n\ndf_drop_timestamp = df_drop_dlc.drop(columns=['Timestamp'], inplace=False).copy()\ndf_drop_timestamp.describe()\n\n","metadata":{"execution":{"iopub.status.busy":"2025-04-10T01:35:48.982414Z","iopub.execute_input":"2025-04-10T01:35:48.982701Z","iopub.status.idle":"2025-04-10T01:35:54.337869Z","shell.execute_reply.started":"2025-04-10T01:35:48.982678Z","shell.execute_reply":"2025-04-10T01:35:54.336666Z"},"trusted":true},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"         CAN ID    DATA0    DATA1    DATA2    DATA3    DATA4    DATA5  \\\ncount   3665770  3665770  3665770  3665770  3665770  3665770  3665770   \nunique       27      108       71       75       26      190      256   \ntop        0000       00       00       00       00       00       00   \nfreq     587521  1623283  1850549  2391587  1989884  1973752  1595567   \n\n          DATA6    DATA7     Flag  \ncount   3665770  3665770  3665770  \nunique       75      256        2  \ntop          00       00        R  \nfreq    2266679  2171246  3078249  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CAN ID</th>\n      <th>DATA0</th>\n      <th>DATA1</th>\n      <th>DATA2</th>\n      <th>DATA3</th>\n      <th>DATA4</th>\n      <th>DATA5</th>\n      <th>DATA6</th>\n      <th>DATA7</th>\n      <th>Flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3665770</td>\n      <td>3665770</td>\n      <td>3665770</td>\n      <td>3665770</td>\n      <td>3665770</td>\n      <td>3665770</td>\n      <td>3665770</td>\n      <td>3665770</td>\n      <td>3665770</td>\n      <td>3665770</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>27</td>\n      <td>108</td>\n      <td>71</td>\n      <td>75</td>\n      <td>26</td>\n      <td>190</td>\n      <td>256</td>\n      <td>75</td>\n      <td>256</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>0000</td>\n      <td>00</td>\n      <td>00</td>\n      <td>00</td>\n      <td>00</td>\n      <td>00</td>\n      <td>00</td>\n      <td>00</td>\n      <td>00</td>\n      <td>R</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>587521</td>\n      <td>1623283</td>\n      <td>1850549</td>\n      <td>2391587</td>\n      <td>1989884</td>\n      <td>1973752</td>\n      <td>1595567</td>\n      <td>2266679</td>\n      <td>2171246</td>\n      <td>3078249</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"data_columns = ['DATA0', 'DATA1', 'DATA2', 'DATA3', 'DATA4', 'DATA5', 'DATA6', 'DATA7']\n\n# Create regex pattern for valid hex\nhex_pattern = r'^[0-9A-Fa-f]{2}$'\n\n# Check for non-hex values\nmask = df_6[data_columns].apply(lambda col: ~col.str.match(hex_pattern, na=False))\n\n# Get rows with any invalid entries\ninvalid_rows = df_6[mask.any(axis=1)]\n\nprint(\"Rows with non-hex values in DATA columns:\")\nprint(invalid_rows if not invalid_rows.empty else \"No non-hex values found\")","metadata":{"execution":{"iopub.status.busy":"2025-04-10T01:35:54.339192Z","iopub.execute_input":"2025-04-10T01:35:54.339592Z","iopub.status.idle":"2025-04-10T01:36:07.591254Z","shell.execute_reply.started":"2025-04-10T01:35:54.339562Z","shell.execute_reply":"2025-04-10T01:36:07.590258Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Rows with non-hex values in DATA columns:\nNo non-hex values found\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"df_7 = df_6.copy()\n# Function to convert hex to decimal\ndef hex_to_int(hex_str: str) -> int:\n    try:\n        return int(str(hex_str).strip(), 16)  # Convert hex to int\n    except ValueError:\n        return np.nan \n\n# Convert all DATA columns\nfor col in df_7.columns[1:-1]:  # Exclude 'Flag' column\n    df_7[col] = df_7[col].apply(hex_to_int)\n\ndf_7.head()","metadata":{"execution":{"iopub.status.busy":"2025-04-10T01:36:07.592253Z","iopub.execute_input":"2025-04-10T01:36:07.592577Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_8 = df_7.copy()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_8[\"Flag\"] = df_8[\"Flag\"].map({\"R\": 0, \"T\": 1})\ndf_8.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_8[\"Flag\"].unique()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_8.isna().sum()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_8.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_8.describe()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Exclude the 'Flag' column before calculating correlation\ncorrelation_matrix = df_8.drop(columns=['Timestamp', 'CAN ID', 'Flag']).corr()\ncorrelation_matrix","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Create directory for images if it doesn't exist\n# image_dir = os.path.join(\"..\", \"images\", \"dos\")\n# os.makedirs(image_dir, exist_ok=True)\n\n\n# Assuming 'correlation_matrix' is already computed\nfig, ax = plt.subplots(figsize=(8, 6))  # Set fixed width (10) and height (8)\n\n# Plot the correlation matrix as a heatmap\nsns.heatmap(correlation_matrix, annot=True, fmt='.2f', linewidths=0.5, ax=ax)\n\n# Save the plot as a PNG image with a fixed size\nplt.tight_layout()  # Ensures proper layout\nplt.savefig(\"correlation_matrix.pdf\", format=\"pdf\", bbox_inches='tight')\n\n\n# Show the plot\nplt.show()\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_9 = df_8.copy()\ndf_9.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Realistic Scenario with no CAN ID included\n\n## Algorithm Selection XGB","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport xgboost as xgb\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, roc_curve, auc\n\n# Load data\ndf = df_9.drop(columns=['Timestamp']).copy()\n\n# 1. Preprocessing\n# Convert CAN ID to numerical (already done as 0 for attacks)\ndf['CAN ID'] = df['CAN ID'].astype('int64')\n\n# 2. Define features and target variable\nX = df.drop(['Flag', 'CAN ID'], axis=1)  # Remove the leakage feature\ny = df['Flag']\n\n# 3. Split data with stratification\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, \n    test_size=0.2, \n    stratify=y, \n    random_state=42\n)\n\n# 4. Initialize XGBoost with realistic parameters\nmodel = xgb.XGBClassifier(\n    scale_pos_weight=8,\n    objective='binary:logistic',\n    eval_metric='aucpr',\n    max_depth=6,  # Prevent overfitting\n    subsample=0.8,\n    colsample_bytree=0.8,\n    random_state=42\n)\n\n# 5. Train the model\nmodel.fit(X_train, y_train)\n\n# 6. Evaluate\ny_pred = model.predict(X_test)\ny_proba = model.predict_proba(X_test)[:, 1]\n\n# Print metrics\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\nprint(f\"\\nROC AUC Score: {roc_auc_score(y_test, y_proba):.4f}\")\n\n# 7. Feature Importance\nplt.figure(figsize=(8, 6))\nxgb.plot_importance(model, ax=plt.gca())\nplt.tight_layout()\nplt.savefig(os.path.join(\"feature_importance_1.pdf\"), format=\"pdf\", bbox_inches='tight')\nplt.show()\n# 1. Plot Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.tight_layout()\nplt.savefig(\"confusion_matrix_1.pdf\", format=\"pdf\", bbox_inches='tight')\nplt.show()\n\n# 2. Plot ROC Curve\nfpr, tpr, thresholds = roc_curve(y_test, y_proba)\nroc_auc = auc(fpr, tpr)\n\nplt.figure(figsize=(8, 6))\nplt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.4f})')\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc=\"lower right\")\nplt.tight_layout()\nplt.savefig(\"roc_curve_1.pdf\", format=\"pdf\", bbox_inches='tight')\n\nplt.show()\n","metadata":{"execution":{"execution_failed":"2025-04-10T01:34:20.012Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##  Advanced Feature Engineering","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve\nimport xgboost as xgb\n\n# Load dataset\ndf = df_9.drop(columns=['Timestamp']).copy()\nprint(df.columns)\n\n# Ensure numeric conversion\nfor col in ['DATA0', 'DATA1', 'DATA5', 'DATA7']:\n    df[col] = pd.to_numeric(df[col], errors='coerce')\n\n# Drop NaN values if necessary\ndf = df.dropna(subset=['DATA0', 'DATA1', 'DATA5', 'DATA7', 'Flag'])\n\n# Define feature columns and target\nfeatures = ['DATA0', 'DATA1', 'DATA5', 'DATA7']\nX = df[features]\ny = df['Flag']  # Target: 1 = Attack, 0 = Normal\n\n# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train XGBoost model\nmodel = xgb.XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.1, eval_metric=\"logloss\")\nmodel.fit(X_train, y_train)\n\n# Predictions\ny_pred = model.predict(X_test)\ny_proba = model.predict_proba(X_test)[:, 1]  # Probability scores\n\n# Performance Metrics\nprint(classification_report(y_test, y_pred))\nroc_auc = roc_auc_score(y_test, y_proba)\nprint(f\"ROC AUC Score: {roc_auc:.4f}\")\n\n# Precision-Recall Curve & Optimal Threshold\n# precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n# target_recall = 0.95\n# idx = np.argmax(recall >= target_recall)\n# optimal_threshold = thresholds[idx]\n# print(f\"Optimal Decision Threshold: {optimal_threshold:.2f}\")\n\n# best_idx = np.argmax(precision * recall)  # F1-score based tuning\n# best_threshold = thresholds[best_idx]\n# print(f\"New Optimal Threshold: {best_threshold:.2f}\")\n\n\n# Function to plot distributions\ndef plot_distribution(feature):\n    plt.figure(figsize=(8, 5))\n    sns.histplot(df[df['Flag'] == 0][feature], label='Normal', color='blue', kde=True, alpha=0.6)\n    sns.histplot(df[df['Flag'] == 1][feature], label='Attack', color='red', kde=True, alpha=0.6)\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(f\"{feature}_distribution.pdf\", format=\"pdf\", bbox_inches='tight')\n    plt.show()\n\n# Plot distributions separately\nfor feature in ['DATA0', 'DATA1']:\n    plot_distribution(feature)\n\n# Feature Engineering (Bitwise & Arithmetic Transformations)\ndf['DATA01_XOR'] = df['DATA0'] ^ df['DATA1']\ndf['DATA01_SUM'] = df['DATA0'] + df['DATA1']\ndf['DATA57_XOR'] = df['DATA5'] ^ df['DATA7']\n\nprint(df[['DATA01_XOR', 'DATA01_SUM', 'DATA57_XOR']].describe())\n\n# Train again with engineered features\nX_new = df[['DATA0', 'DATA1', 'DATA5', 'DATA7', 'DATA01_XOR', 'DATA01_SUM', 'DATA57_XOR']]\nX_train_new, X_test_new, y_train, y_test = train_test_split(X_new, y, test_size=0.2, random_state=42)\nmodel.fit(X_train_new, y_train)\n\n# Evaluate again\ny_pred_new = model.predict(X_test_new)\nprint(classification_report(y_test, y_pred_new))\n\n# Compute confusion matrix\ncm = confusion_matrix(y_test, y_pred)\n\n# Plot the confusion matrix as a heatmap\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Normal\", \"Attack\"], yticklabels=[\"Normal\", \"Attack\"])\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\nplt.tight_layout()\nplt.savefig(\"confusion_matrix_2.pdf\", format=\"pdf\", bbox_inches='tight')\nplt.show()\n","metadata":{"execution":{"execution_failed":"2025-04-10T01:34:20.012Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Initial Model Confusion Matrix\ncm_initial = confusion_matrix(y_test, y_pred)\n\n# Plot Initial Confusion Matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm_initial, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal', 'Attack'], yticklabels=['Normal', 'Attack'])\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.tight_layout()\nplt.savefig(os.path.join(\"confusion_matrix_initial.pdf\"), format=\"pdf\", bbox_inches='tight')\nplt.show()\n\n# Retrained Model Confusion Matrix\ncm_retrained = confusion_matrix(y_test, y_pred_new)\n\n# Plot Retrained Confusion Matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm_retrained, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal', 'Attack'], yticklabels=['Normal', 'Attack'])\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.tight_layout()\nplt.savefig(os.path.join(\"confusion_matrix_retrained.pdf\"), format=\"pdf\", bbox_inches='tight')\nplt.show()\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-10T01:34:20.012Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_9.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T01:34:53.808213Z","iopub.execute_input":"2025-04-10T01:34:53.808560Z","iopub.status.idle":"2025-04-10T01:34:53.897945Z","shell.execute_reply.started":"2025-04-10T01:34:53.808532Z","shell.execute_reply":"2025-04-10T01:34:53.896182Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-34b684fddf65>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_9\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'df_9' is not defined"],"ename":"NameError","evalue":"name 'df_9' is not defined","output_type":"error"}],"execution_count":1},{"cell_type":"markdown","source":"## Temporal Features","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import StratifiedKFold\nimport xgboost as xgb\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score, roc_curve\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom imblearn.over_sampling import SMOTE\n\n\n# Load data\ndf = df_9.copy()\ndf['Timestamp'] = pd.to_datetime(df['Timestamp'], unit='s')\ndf = df.sort_values('Timestamp').reset_index(drop=True)\ndf.set_index('Timestamp', inplace=True)\n\n# Feature Engineering\ndf['Global_Time_Delta'] = df.index.to_series().diff().dt.total_seconds().fillna(0)\ndf['Rolling_Count_1ms'] = df.rolling('1ms').count()['CAN ID']\ndf['Rolling_Count_10ms'] = df.rolling('10ms').count()['CAN ID']\ndf['Rolling_Count_1ms'] = df.rolling('0.3ms').count()['CAN ID']\ndf['Hour'] = df.index.hour\ndf['Time_Since_First_Message'] = (df.index - df.index.min()).total_seconds()\n\n# Prepare features\nX = df.drop(['Flag', 'CAN ID'], axis=1)\ny = df['Flag']\n\n# Apply SMOTE\nsmote = SMOTE(sampling_strategy='auto', random_state=42)\nX_res, y_res = smote.fit_resample(X, y)\n\n# Initialize XGBoost\nmodel = xgb.XGBClassifier(\n    scale_pos_weight=10, \n    objective='binary:logistic',\n    eval_metric='aucpr',\n    max_depth=6,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    random_state=42\n)\n\n# Stratified K-Fold\nkf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n# Metrics storage\nroc_auc_scores, accuracies, classification_reports, confusion_matrices = [], [], [], []\nall_fpr, all_tpr = [], []\n\n# Cross-validation loop\nfor train_index, test_index in kf.split(X_res, y_res):\n    X_train, X_test = X_res.iloc[train_index], X_res.iloc[test_index]\n    y_train, y_test = y_res.iloc[train_index], y_res.iloc[test_index]\n\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    y_proba = model.predict_proba(X_test)[:, 1]\n\n    accuracies.append(accuracy_score(y_test, y_pred))\n    roc_auc_scores.append(roc_auc_score(y_test, y_proba))\n    classification_reports.append(classification_report(y_test, y_pred))\n    confusion_matrices.append(confusion_matrix(y_test, y_pred))\n\n    # Compute ROC curve\n    fpr, tpr, _ = roc_curve(y_test, y_proba)\n    all_fpr.append(fpr)\n    all_tpr.append(tpr)\n\n# Compute final averages\navg_accuracy = np.mean(accuracies)\navg_roc_auc = np.mean(roc_auc_scores)\navg_conf_matrix = np.sum(confusion_matrices, axis=0).astype(int)\n\nprint(f\"Average Accuracy: {avg_accuracy:.4f}\")\nprint(f\"Average ROC AUC Score: {avg_roc_auc:.4f}\")\nprint(f\"\\nAverage Confusion Matrix:\\n {avg_conf_matrix}\")\nprint(\"\\nClassification Report (Example Fold):\\n\", classification_reports[0])\n\n# Feature Importance\nimportances = model.get_booster().get_score(importance_type='gain')\nnormalized_importances = {k: v / sum(importances.values()) for k, v in importances.items()}\nfeature_importance_df = pd.DataFrame(list(normalized_importances.items()), columns=['Feature', 'Importance'])\nfeature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n\n# Plot Feature Importance\nplt.figure(figsize=(10, 6))\nxgb.plot_importance(model, importance_type='gain', ax=plt.gca())\nplt.tight_layout()\nplt.savefig(os.path.join(\"feature_importance_3.pdf\"), format=\"pdf\", bbox_inches='tight')\nplt.show()\n\n# Heatmap of Feature Importance\nplt.figure(figsize=(10, 6))\nsns.heatmap(feature_importance_df.set_index('Feature').T, annot=True, cmap='coolwarm', fmt='.3f')\nplt.tight_layout()\nplt.savefig(\"feature_importance_heatmap_3.pdf\", format=\"pdf\", bbox_inches='tight')\nplt.show()\n\n# Average ROC Curve\nplt.figure(figsize=(8, 6))\nfor fpr, tpr in zip(all_fpr, all_tpr):\n    plt.plot(fpr, tpr, alpha=0.3)  # Plot all folds\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.tight_layout()\nplt.savefig(os.path.join(\"roc_curve_3.pdf\"), format=\"pdf\", bbox_inches='tight')\nplt.show()\n\n# Confusion Matrix Heatmap\nplt.figure(figsize=(8, 6))\nsns.heatmap(avg_conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal', 'DoS Attack'], yticklabels=['Normal', 'DoS Attack'])\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.tight_layout()\nplt.savefig(os.path.join(\"confusion_matrix_3.pdf\"), format=\"pdf\", bbox_inches='tight')\nplt.show()\n","metadata":{"execution":{"execution_failed":"2025-04-10T01:34:20.013Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Updated Confusion Matrix:\n```\ncm = [[605815   9834]\n      [    72 615578]]\n```\n\n### Explanation:\n- **True Positives (TP)**: The number of instances correctly predicted as **Class 1** (attack).\n  - **615578** (bottom-right cell)\n  \n- **False Positives (FP)**: The number of instances incorrectly predicted as **Class 1** when they are actually **Class 0** (normal).\n  - **9834** (top-right cell)\n\n- **True Negatives (TN)**: The number of instances correctly predicted as **Class 0** (normal).\n  - **605815** (top-left cell)\n\n- **False Negatives (FN)**: The number of instances incorrectly predicted as **Class 0** when they are actually **Class 1**.\n  - **72** (bottom-left cell)\n\n### Now, let's compute some key metrics:\n\n1. **Accuracy**: The overall percentage of correct predictions.\n   \\[\n   \\text{Accuracy} = \\frac{TP + TN}{TP + FP + TN + FN}\n   \\]\n   \\[\n   \\text{Accuracy} = \\frac{615578 + 605815}{615578 + 9834 + 605815 + 72} = \\frac{1227393}{1227399} \\approx 0.99995\n   \\]\n   **Accuracy ≈ 99.995%**\n\n2. **Precision for Class 1 (attack)**: The percentage of predicted positive instances (Class 1) that are actually positive.\n   \\[\n   \\text{Precision (Class 1)} = \\frac{TP}{TP + FP} = \\frac{615578}{615578 + 9834} \\approx 0.983\n   \\]\n   **Precision (Class 1) ≈ 98.3%**\n\n3. **Recall for Class 1 (attack)**: The percentage of actual positive instances (Class 1) that were correctly identified.\n   \\[\n   \\text{Recall (Class 1)} = \\frac{TP}{TP + FN} = \\frac{615578}{615578 + 72} \\approx 0.99988\n   \\]\n   **Recall (Class 1) ≈ 99.99%**\n\n4. **F1 Score for Class 1**: The harmonic mean of precision and recall.\n   \\[\n   \\text{F1 Score (Class 1)} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}} \\approx 2 \\times \\frac{0.983 \\times 0.99988}{0.983 + 0.99988} \\approx 0.991\n   \\]\n   **F1 Score (Class 1) ≈ 99.1%**\n\n5. **Precision for Class 0 (normal)**: The percentage of predicted negative instances (Class 0) that are actually negative.\n   \\[\n   \\text{Precision (Class 0)} = \\frac{TN}{TN + FN} = \\frac{605815}{605815 + 72} \\approx 0.99988\n   \\]\n   **Precision (Class 0) ≈ 99.99%**\n\n6. **Recall for Class 0 (normal)**: The percentage of actual negative instances (Class 0) that were correctly identified.\n   \\[\n   \\text{Recall (Class 0)} = \\frac{TN}{TN + FP} = \\frac{605815}{605815 + 9834} \\approx 0.984\n   \\]\n   **Recall (Class 0) ≈ 98.4%**\n\n7. **F1 Score for Class 0**: The harmonic mean of precision and recall for Class 0.\n   \\[\n   \\text{F1 Score (Class 0)} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}} \\approx 2 \\times \\frac{0.99988 \\times 0.984}{0.99988 + 0.984} \\approx 0.992\n   \\]\n   **F1 Score (Class 0) ≈ 99.2%**\n\n### Conclusion:\n- **Accuracy**: 99.995%, which suggests that the model is correct nearly 100% of the time.\n- **For Class 1 (attack)**: The model performs very well with a high **precision** (98.3%) and **recall** (99.99%), making it excellent at detecting **attacks**.\n- **For Class 0 (normal)**: The model also performs excellently for **normal** instances with a **precision** of 99.99% and **recall** of 98.4%.\n\nThe model appears to be performing very well overall, especially for both classes. The **attack class** (Class 1) has very few false negatives, and the **normal class** (Class 0) has very few false positives. However, you may want to look into **class imbalance**, since the numbers of instances of Class 1 and Class 0 may be quite different. But for this case, the model is performing well in distinguishing both classes.","metadata":{}},{"cell_type":"markdown","source":"### SMOTE applie only to training data","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import StratifiedKFold\nimport xgboost as xgb\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score, roc_curve\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom imblearn.over_sampling import SMOTE\n\n# Load and preprocess data\ndf = df_9.copy()\ndf['Timestamp'] = pd.to_datetime(df['Timestamp'], unit='s')\ndf = df.sort_values('Timestamp').reset_index(drop=True)\ndf.set_index('Timestamp', inplace=True)\n\n# Feature Engineering\ndf['Global_Time_Delta'] = df.index.to_series().diff().dt.total_seconds().fillna(0)\ndf['Rolling_Count_1ms'] = df.rolling('1ms').count()['CAN ID']\ndf['Rolling_Count_10ms'] = df.rolling('10ms').count()['CAN ID']\ndf['Rolling_Count_0.3ms'] = df.rolling('0.3ms').count()['CAN ID']\ndf['Hour'] = df.index.hour\ndf['Time_Since_First_Message'] = (df.index - df.index.min()).total_seconds()\n\n# Prepare features\nX = df.drop(['Flag', 'CAN ID'], axis=1)\ny = df['Flag']\n\n# Initialize model\nmodel = xgb.XGBClassifier(\n    scale_pos_weight=10,\n    objective='binary:logistic',\n    eval_metric='aucpr',\n    max_depth=6,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    random_state=42\n)\n\n# Stratified K-Fold\nkf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n# Metrics storage\nroc_auc_scores, accuracies, classification_reports, confusion_matrices = [], [], [], []\nall_fpr, all_tpr = [], []\n\n# Cross-validation loop\nfor train_index, test_index in kf.split(X, y):\n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n\n    # ✅ Apply SMOTE to training data only\n    smote = SMOTE(sampling_strategy='auto', random_state=42)\n    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n\n    model.fit(X_train_res, y_train_res)\n\n    y_pred = model.predict(X_test)\n    y_proba = model.predict_proba(X_test)[:, 1]\n\n    accuracies.append(accuracy_score(y_test, y_pred))\n    roc_auc_scores.append(roc_auc_score(y_test, y_proba))\n    classification_reports.append(classification_report(y_test, y_pred))\n    confusion_matrices.append(confusion_matrix(y_test, y_pred))\n\n    fpr, tpr, _ = roc_curve(y_test, y_proba)\n    all_fpr.append(fpr)\n    all_tpr.append(tpr)\n\n# Averages\navg_accuracy = np.mean(accuracies)\navg_roc_auc = np.mean(roc_auc_scores)\navg_conf_matrix = np.sum(confusion_matrices, axis=0).astype(int)\n\n# Results\nprint(f\"Average Accuracy: {avg_accuracy:.4f}\")\nprint(f\"Average ROC AUC Score: {avg_roc_auc:.4f}\")\nprint(f\"\\nAverage Confusion Matrix:\\n{avg_conf_matrix}\")\nprint(\"\\nClassification Report (Example Fold):\\n\", classification_reports[0])\n\n# Feature Importance\nimportances = model.get_booster().get_score(importance_type='gain')\nnormalized_importances = {k: v / sum(importances.values()) for k, v in importances.items()}\nfeature_importance_df = pd.DataFrame(list(normalized_importances.items()), columns=['Feature', 'Importance'])\nfeature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n\n# Plot Feature Importance\nplt.figure(figsize=(10, 6))\nxgb.plot_importance(model, importance_type='gain', ax=plt.gca())\nplt.tight_layout()\nplt.savefig(\"feature_importance_train_smote.pdf\", format=\"pdf\", bbox_inches='tight')\nplt.show()\n\n# Heatmap of Feature Importance\nplt.figure(figsize=(10, 6))\nsns.heatmap(feature_importance_df.set_index('Feature').T, annot=True, cmap='coolwarm', fmt='.3f')\nplt.tight_layout()\nplt.savefig(\"feature_importance_heatmap_train_smote.pdf\", format=\"pdf\", bbox_inches='tight')\nplt.show()\n\n# Average ROC Curve\nplt.figure(figsize=(8, 6))\nfor fpr, tpr in zip(all_fpr, all_tpr):\n    plt.plot(fpr, tpr, alpha=0.3)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.tight_layout()\nplt.savefig(\"roc_curve_train_smote.pdf\", format=\"pdf\", bbox_inches='tight')\nplt.show()\n\n# Confusion Matrix Heatmap\nplt.figure(figsize=(8, 6))\nsns.heatmap(avg_conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal', 'Attack'], yticklabels=['Normal', 'Attack'])\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.tight_layout()\nplt.savefig(\"confusion_matrix_train_smote.pdf\", format=\"pdf\", bbox_inches='tight')\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Algorithm RF\n","metadata":{}},{"cell_type":"markdown","source":"## Without SMOTE","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\n\n# Load data\ndf = df_9.copy()\n\n# 1. Preprocessing\n# Convert CAN ID to categorical (important for tree models)\ndf['CAN ID'] = df['CAN ID'].astype('category')\n\n# 2. Split data\nX = df.drop('Flag', axis=1)\ny = df['Flag']\n\n# Stratified split to maintain class balance\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, \n    test_size=0.2, \n    stratify=y,\n    random_state=42\n)\n\n# 3. Initialize Random Forest with class weighting\nrf = RandomForestClassifier(\n    n_estimators=100,\n    class_weight='balanced',  # Handles imbalance\n    max_depth=10,             # Prevent overfitting\n    n_jobs=-1,                # Use all cores\n    random_state=42\n)\n\n# 4. Train model\nrf.fit(X_train, y_train)\n\n# 5. Evaluate\ny_pred = rf.predict(X_test)\ny_proba = rf.predict_proba(X_test)[:,1]\n\n# Evaluate model performance\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n\nprint(f\"\\nROC AUC Score: {roc_auc_score(y_test, y_proba):.4f}\")\n\n# 6. Feature Importance\nfeatures = X.columns\nimportances = rf.feature_importances_\nstd = np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)\n\n# Create DataFrame\nfi_df = pd.DataFrame({'Feature': features, 'Importance': importances, 'Std': std})\nfi_df = fi_df.sort_values('Importance', ascending=False)\n\n# Plot Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.tight_layout()\nplt.savefig(os.path.join(\"confusion_matrix_rf_1.pdf\"), format=\"pdf\", bbox_inches='tight')\nplt.show()\n\n# Plot\nplt.figure(figsize=(10,6))\nplt.bar(fi_df['Feature'], fi_df['Importance'], yerr=fi_df['Std'])\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.savefig(os.path.join(\"feature_imp_rf_1.pdf\"), format=\"pdf\", bbox_inches='tight')\nplt.show()\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-10T01:34:20.013Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Class Weight Tuning","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score\nimport matplotlib.pyplot as plt\n\n# Load data\ndf = df_9.copy()\n\n\n# 2. Split data\nX = df.drop(['Timestamp', 'Flag', 'CAN ID'], axis=1)  # Remove the leakage feature\ny = df['Flag']\n\n# Stratified split to maintain class balance\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, \n    test_size=0.2, \n    stratify=y,\n    random_state=42\n)\n\n# 3. Manually calculate class weights based on the exact class ratio (~5.24:1)\n# ratio = 3_078_250 / 587_521  # approximately 5.24\nratio = 10\nclass_weights = {0: 1, 1: ratio}  # Assign higher weight to minority class\n\n# 4. Initialize Random Forest with manually calculated class weights\nrf = RandomForestClassifier(\n    n_estimators=100,\n    class_weight=class_weights,  # using manual weights instead of 'balanced'\n    max_depth=10,                # Prevent overfitting\n    n_jobs=-1,                   # Use all available cores\n    random_state=42\n)\n\n# 5. Train the model\nrf.fit(X_train, y_train)\n\n# 6. Evaluate the model\ny_pred = rf.predict(X_test)\ny_proba = rf.predict_proba(X_test)[:, 1]\n\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\nprint(f\"\\nROC AUC Score: {roc_auc_score(y_test, y_proba):.4f}\")\n\n# 7. Feature Importance\nfeatures = X.columns\nimportances = rf.feature_importances_\nstd = np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)\n\n# Create DataFrame for feature importances\nfi_df = pd.DataFrame({'Feature': features, 'Importance': importances, 'Std': std})\nfi_df = fi_df.sort_values('Importance', ascending=False)\n\n# Plot Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.tight_layout()\nplt.savefig(os.path.join(\"confusion_matrix_rf_2.pdf\"), format=\"pdf\", bbox_inches='tight')\nplt.show()\n\n# Plot feature importances\nplt.figure(figsize=(10, 6))\nplt.bar(fi_df['Feature'], fi_df['Importance'], yerr=fi_df['Std'])\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.savefig(os.path.join(\"feature_imp_rf.pdf\"), format=\"pdf\", bbox_inches='tight')\nplt.show()\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-10T01:34:20.013Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Threshold Adjustment","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport xgboost as xgb\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score, precision_recall_curve\nimport matplotlib.pyplot as plt\n\n# Load data\ndf = df_9.copy()\n\n\nX = df.drop(['Timestamp', 'Flag', 'CAN ID'], axis=1)  # Remove the leakage feature\ny = df['Flag']\n\n# 3. Split data with stratification to maintain class balance\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, \n    test_size=0.2, \n    stratify=y, \n    random_state=42\n)\n\n# 4. Initialize XGBoost classifier with built-in imbalance handling\nmodel = xgb.XGBClassifier(\n    scale_pos_weight=5.24,      # Directly accounts for the class imbalance ratio\n    objective='binary:logistic',\n    eval_metric='aucpr',        # Optimize for precision-recall AUC\n    use_label_encoder=False,    # Suppress a warning regarding label encoding\n    random_state=42\n)\n\n# 5. Train the model\nmodel.fit(X_train, y_train)\n\n# 6. Get predicted probabilities for the positive class\ny_proba = model.predict_proba(X_test)[:, 1]\n\n# 7. Threshold Adjustment: Optimize decision threshold using precision-recall curve\nprecision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n\n# Compute F1 scores for each threshold; note that thresholds array is one element shorter than precision/recall\nf1_scores = 2 * precision[:-1] * recall[:-1] / (precision[:-1] + recall[:-1] + 1e-8)  # avoid division by zero\nbest_idx = np.argmax(f1_scores)\nbest_threshold = thresholds[best_idx]\nprint(f\"Optimal Threshold (based on maximum F1): {best_threshold:.4f}\")\n\n# Use the optimal threshold to make final predictions\ny_pred = (y_proba >= best_threshold).astype(int)\n\n# 8. Evaluate the model with the adjusted threshold\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\nprint(f\"\\nROC AUC Score: {roc_auc_score(y_test, y_proba):.4f}\")\n\n# Plot Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.tight_layout()\nplt.savefig(os.path.join(\"confusion_matrix_rf_3.pdf\"), format=\"pdf\", bbox_inches='tight')\n\nplt.show()\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-10T01:34:20.013Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## With SMOTE and KFold","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score, roc_curve\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom imblearn.over_sampling import SMOTE  # Import SMOTE\n\n# Ensure directory exists for saving plots\nimage_dir = \"../images\"\nos.makedirs(image_dir, exist_ok=True)\n\n# Load data\ndf = df_9.copy()\n\n# Prepare Features and Target\nX = df.drop(['Timestamp','Flag', 'CAN ID'], axis=1)  # Remove 'Flag' (target) and 'CAN ID' (identifier)\ny = df['Flag']\n\n# Apply SMOTE\nsmote = SMOTE(sampling_strategy='auto', random_state=42)\n\n# Initialize Random Forest with Class Weighting\nrf = RandomForestClassifier(\n    n_estimators=10,\n    class_weight='balanced',  # Handles imbalance\n    max_depth=10,             # Prevent overfitting\n    n_jobs=-1,                # Use all CPU cores\n    random_state=42\n)\n\n# Stratified K-Fold\nkf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n# Metrics storage\nroc_auc_scores, accuracies, classification_reports, confusion_matrices = [], [], [], []\nall_fpr, all_tpr = [], []\n\n# Cross-validation loop\nfor train_index, test_index in kf.split(X, y):\n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n\n    # Apply SMOTE to the training set only\n    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n\n    # Train the Model on Resampled Data\n    rf.fit(X_train_res, y_train_res)\n\n    # Make predictions\n    y_pred = rf.predict(X_test)\n    y_proba = rf.predict_proba(X_test)[:,1]  # Get probability of the positive class\n\n    # Store performance metrics\n    accuracies.append(accuracy_score(y_test, y_pred))\n    roc_auc_scores.append(roc_auc_score(y_test, y_proba))\n    classification_reports.append(classification_report(y_test, y_pred))\n    confusion_matrices.append(confusion_matrix(y_test, y_pred))\n\n    # Compute ROC curve\n    fpr, tpr, _ = roc_curve(y_test, y_proba)\n    all_fpr.append(fpr)\n    all_tpr.append(tpr)\n\n# Compute final averages\navg_accuracy = np.mean(accuracies)\navg_roc_auc = np.mean(roc_auc_scores)\navg_conf_matrix = np.sum(confusion_matrices, axis=0).astype(int)\n\nprint(f\"Average Accuracy: {avg_accuracy:.4f}\")\nprint(f\"Average ROC AUC Score: {avg_roc_auc:.4f}\")\nprint(f\"\\nAverage Confusion Matrix:\\n {avg_conf_matrix}\")\nprint(\"\\nClassification Report (Example Fold):\\n\", classification_reports[0])\n\n# Average ROC Curve\nplt.figure(figsize=(8, 6))\nfor fpr, tpr in zip(all_fpr, all_tpr):\n    plt.plot(fpr, tpr, alpha=0.3)  # Plot all folds\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title(f'Average ROC Curve (AUC = {avg_roc_auc:.4f})')\nplt.tight_layout()\nplt.savefig(os.path.join(image_dir, \"roc_curve_rf.pdf\"), format=\"pdf\", bbox_inches='tight')\nplt.show()\n\n# Average Confusion Matrix Heatmap\nplt.figure(figsize=(8, 6))\nsns.heatmap(avg_conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal', 'DoS Attack'], yticklabels=['Normal', 'DoS Attack'])\nplt.title('Average Confusion Matrix (Random Forest)')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.tight_layout()\nplt.savefig(os.path.join(image_dir, \"confusion_matrix_rf.pdf\"), format=\"pdf\", bbox_inches='tight')\nplt.show()\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-10T01:34:20.013Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## SMOTE but no KFold","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score\nfrom imblearn.over_sampling import SMOTE  # Import SMOTE\nimport matplotlib.pyplot as plt\n\n# Load data\ndf = df_9.copy()\n\n# 1. Prepare Features and Target\nX = df.drop(['Timestamp','Flag', 'CAN ID'], axis=1)  # Remove 'Timestamp' 'Flag' (target) and 'CAN ID' (identifier)\ny = df['Flag']\n\n# 2. Stratified Train-Test Split\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, \n    test_size=0.2, \n    stratify=y,\n    random_state=42\n)\n\n# 3. Apply SMOTE for Oversampling\nsmote = SMOTE(sampling_strategy='auto', random_state=42)\nX_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n\n# Print class distribution before and after SMOTE\nprint(f\"Before SMOTE: {np.bincount(y_train)}\")\nprint(f\"After SMOTE: {np.bincount(y_train_res)}\")\n\n# 4. Initialize Random Forest with Class Weighting\nrf = RandomForestClassifier(\n    n_estimators=20,\n    class_weight='balanced',  # Handles imbalance\n    max_depth=10,             # Prevent overfitting\n    n_jobs=-1,                # Use all CPU cores\n    random_state=42\n)\n\n# 5. Train the Model on Resampled Data\nrf.fit(X_train_res, y_train_res)\n\n# 6. Evaluate on Test Set\ny_pred = rf.predict(X_test)\ny_proba = rf.predict_proba(X_test)[:,1]  # Get probability of the positive class\n\n# Performance Metrics\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\nprint(f\"\\nROC AUC Score: {roc_auc_score(y_test, y_proba):.4f}\")\n\n\n\n# Plot Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.tight_layout()\nplt.savefig(os.path.join(\"confusion_matrix_rf_2.pdf\"), format=\"pdf\", bbox_inches='tight')\nplt.show()\n\n\n# Before SMOTE: [2462599  470017]\n# After SMOTE: [2462599 2462599]\n# Accuracy: 0.9766351953341317\n# Confusion Matrix:\n#  [[598520  17130]\n#  [     0 117504]]\n# Classification Report:\n#                precision    recall  f1-score   support\n\n#            0       1.00      0.97      0.99    615650\n#            1       0.87      1.00      0.93    117504\n\n#     accuracy                           0.98    733154\n#    macro avg       0.94      0.99      0.96    733154\n# weighted avg       0.98      0.98      0.98    733154\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-10T01:34:20.013Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# SVM Model","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Load data\ndf = df_9.copy()\n\n# 1. Prepare Features and Target\nX = df.drop(['Timestamp', 'Flag', 'CAN ID'], axis=1)  # Remove 'Flag' (target) and 'CAN ID' (identifier)\ny = df['Flag']\n\n# 2. Stratified Train-Test Split\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, \n    test_size=0.2, \n    stratify=y,\n    random_state=42\n)\n\n# Print class distribution before splitting\nprint(f\"Class distribution in training set: {np.bincount(y_train)}\")\n\n# 3. Initialize SVM with Class Weighting\nsvm = SVC(\n    kernel='rbf',            # 'linear' can be used for high-dimensional sparse data\n    class_weight='balanced',  # Handle class imbalance\n    probability=True,         # Enable probability estimates (needed for ROC AUC)\n    random_state=42\n)\n\n# 4. Train the Model\nsvm.fit(X_train, y_train)\n\n# 5. Evaluate on Test Set\ny_pred = svm.predict(X_test)\ny_proba = svm.predict_proba(X_test)[:, 1]  # Get probability of the positive class\n\n# Performance Metrics\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\nprint(f\"\\nROC AUC Score: {roc_auc_score(y_test, y_proba):.4f}\")\n\n# Plot Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.tight_layout()\nplt.savefig(os.path.join(\"confusion_matrix_svm_1.pdf\"), format=\"pdf\", bbox_inches='tight')\nplt.show()\n\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-10T01:34:20.013Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}